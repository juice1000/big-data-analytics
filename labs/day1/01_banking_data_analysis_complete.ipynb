{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05e261dc",
   "metadata": {},
   "source": [
    "# Banking Data Analysis - Live Coding Workshop\n",
    "## Big Data Analytics im Banking | 13:00-15:40\n",
    "\n",
    "### ðŸŽ¯ **Workshop Agenda**\n",
    "- **13:00-13:45:** EinfÃ¼hrung in Datenanalyse + Banking Transaction Analysis\n",
    "- **13:55-14:40:** Spark Deep-Dive & GCP Setup\n",
    "- **14:50-15:40:** Datenbeschaffung und -integration\n",
    "\n",
    "### ðŸ›  **Was wir heute lernen:**\n",
    "1. **Datenanalyseprozess** in der Praxis\n",
    "2. **Data Mining** fÃ¼r Banking-Patterns\n",
    "3. **Spark Setup** und SQL-Queries\n",
    "4. **GCP/Databricks** Configuration\n",
    "5. **Web Scraping** fÃ¼r Financial Data\n",
    "6. **Multi-Source Integration**\n",
    "\n",
    "### ðŸ“‹ **Live Coding Approach**\n",
    "- **Instructor demonstrates** â†’ **Students modify/extend**\n",
    "- **Short code blocks** with thorough comments\n",
    "- **Interactive exercises** at each step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b73afc",
   "metadata": {},
   "source": [
    "## 1. Load Large Banking Transactions (PySpark) ðŸ¦\n",
    "**Goal:** Load a >1GB CSV efficiently using PySpark and prepare it for analysis\n",
    "\n",
    "Dataset: `transactions_data.csv` (set the path below)\n",
    "\n",
    "### ðŸŽ“ Live Coding Exercise:\n",
    "- **Instructor:** Sets up Spark and loads the dataset with an explicit schema or fast inference\n",
    "- **Students:** Add derived columns and validate data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9f66ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/08/10 21:34:12 WARN Utils: Your hostname, Maclook-Bro.local resolves to a loopback address: 127.0.0.1; using 172.18.160.138 instead (on interface en0)\n",
      "25/08/10 21:34:12 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/08/10 21:34:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/08/10 21:34:13 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Spark ready!\n",
      "Version: 3.5.3\n"
     ]
    }
   ],
   "source": [
    "# Simple PySpark setup for banking data\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Dataset path\n",
    "dataset_path = \"../data/transactions_data.csv\"\n",
    "\n",
    "# Create basic Spark session\n",
    "spark = SparkSession.builder.appName(\"Banking Analysis\").getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "print(\"âœ… Spark ready!\")\n",
    "print(f\"Version: {spark.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f01ebe08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Loading banking dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‹ Schema:\n",
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- client_id: integer (nullable = true)\n",
      " |-- card_id: integer (nullable = true)\n",
      " |-- amount: string (nullable = true)\n",
      " |-- use_chip: string (nullable = true)\n",
      " |-- merchant_id: integer (nullable = true)\n",
      " |-- merchant_city: string (nullable = true)\n",
      " |-- merchant_state: string (nullable = true)\n",
      " |-- zip: double (nullable = true)\n",
      " |-- mcc: integer (nullable = true)\n",
      " |-- errors: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:====================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Loaded 13,305,915 transactions\n",
      "+--------------+-------------------+-----------+-------+-------+-----------------+-----------+-------------+--------------+-------+----+------+-------------------+\n",
      "|transaction_id|               date|customer_id|card_id| amount|         use_chip|merchant_id|merchant_city|merchant_state|    zip| mcc|errors|   transaction_date|\n",
      "+--------------+-------------------+-----------+-------+-------+-----------------+-----------+-------------+--------------+-------+----+------+-------------------+\n",
      "|       7475327|2010-01-01 00:01:00|       1556|   2972|$-77.00|Swipe Transaction|      59935|       Beulah|            ND|58523.0|5499|  NULL|2010-01-01 00:01:00|\n",
      "|       7475328|2010-01-01 00:02:00|        561|   4575| $14.57|Swipe Transaction|      67570|   Bettendorf|            IA|52722.0|5311|  NULL|2010-01-01 00:02:00|\n",
      "|       7475329|2010-01-01 00:02:00|       1129|    102| $80.00|Swipe Transaction|      27092|        Vista|            CA|92084.0|4829|  NULL|2010-01-01 00:02:00|\n",
      "|       7475331|2010-01-01 00:05:00|        430|   2860|$200.00|Swipe Transaction|      27092|  Crown Point|            IN|46307.0|4829|  NULL|2010-01-01 00:05:00|\n",
      "|       7475332|2010-01-01 00:06:00|        848|   3915| $46.41|Swipe Transaction|      13051|      Harwood|            MD|20776.0|5813|  NULL|2010-01-01 00:06:00|\n",
      "+--------------+-------------------+-----------+-------+-------+-----------------+-----------+-------------+--------------+-------+----+------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Load and prepare banking data\n",
    "print(\"ðŸ“¦ Loading banking dataset...\")\n",
    "\n",
    "# Simple data loading\n",
    "df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(dataset_path)\n",
    "\n",
    "print(\"ðŸ“‹ Schema:\")\n",
    "df.printSchema()\n",
    "\n",
    "# Basic column mapping\n",
    "df = df.withColumnRenamed(\"client_id\", \"customer_id\") \\\n",
    "       .withColumnRenamed(\"id\", \"transaction_id\") \\\n",
    "       .withColumn(\"transaction_date\", to_timestamp(col(\"date\")))\n",
    "\n",
    "print(f\"ðŸ“Š Loaded {df.count():,} transactions\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "64adc563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Adding basic features...\n",
      "âœ… Amount data types - USD: double\n",
      "âœ… Features added and temp view created!\n",
      "+-----------+----------+-----------------+----+----------+----------+\n",
      "|customer_id|amount_usd|merchant_category|hour|is_weekend|zip_region|\n",
      "+-----------+----------+-----------------+----+----------+----------+\n",
      "|       1556|     -77.0|            Other|   0|     false| Southeast|\n",
      "|        561|     14.57|            Other|   0|     false| Southeast|\n",
      "|       1129|      80.0|            Other|   0|     false|      West|\n",
      "|        430|     200.0|            Other|   0|     false| Southeast|\n",
      "|        848|     46.41|       Restaurant|   0|     false| Northeast|\n",
      "|       1807|      4.81|            Other|   0|     false| Northeast|\n",
      "|       1556|      77.0|            Other|   0|     false| Southeast|\n",
      "|       1684|     26.46|            Other|   0|     false|   Unknown|\n",
      "|        335|    261.58|            Other|   0|     false|   Unknown|\n",
      "|        351|     10.74|       Restaurant|   0|     false| Northeast|\n",
      "|        554|      3.51|            Other|   0|     false|   Central|\n",
      "|        605|      2.58|          Grocery|   0|     false| Northeast|\n",
      "|       1556|     39.63|            Other|   0|     false| Southeast|\n",
      "|       1797|     43.33|            Other|   0|     false|      West|\n",
      "|        114|     49.42|      Gas Station|   0|     false|      West|\n",
      "|       1634|      1.09|            Other|   0|     false|   Central|\n",
      "|        646|     73.79|            Other|   0|     false| Northeast|\n",
      "|       1129|     100.0|            Other|   0|     false|      West|\n",
      "|        394|     26.04|            Other|   0|     false|   Unknown|\n",
      "|        114|     -64.0|      Gas Station|   0|     false|      West|\n",
      "+-----------+----------+-----------------+----+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----------+----------+-----------------+----+----------+----------+\n",
      "|customer_id|amount_usd|merchant_category|hour|is_weekend|zip_region|\n",
      "+-----------+----------+-----------------+----+----------+----------+\n",
      "|       1556|     -77.0|            Other|   0|     false| Southeast|\n",
      "|        561|     14.57|            Other|   0|     false| Southeast|\n",
      "|       1129|      80.0|            Other|   0|     false|      West|\n",
      "|        430|     200.0|            Other|   0|     false| Southeast|\n",
      "|        848|     46.41|       Restaurant|   0|     false| Northeast|\n",
      "|       1807|      4.81|            Other|   0|     false| Northeast|\n",
      "|       1556|      77.0|            Other|   0|     false| Southeast|\n",
      "|       1684|     26.46|            Other|   0|     false|   Unknown|\n",
      "|        335|    261.58|            Other|   0|     false|   Unknown|\n",
      "|        351|     10.74|       Restaurant|   0|     false| Northeast|\n",
      "|        554|      3.51|            Other|   0|     false|   Central|\n",
      "|        605|      2.58|          Grocery|   0|     false| Northeast|\n",
      "|       1556|     39.63|            Other|   0|     false| Southeast|\n",
      "|       1797|     43.33|            Other|   0|     false|      West|\n",
      "|        114|     49.42|      Gas Station|   0|     false|      West|\n",
      "|       1634|      1.09|            Other|   0|     false|   Central|\n",
      "|        646|     73.79|            Other|   0|     false| Northeast|\n",
      "|       1129|     100.0|            Other|   0|     false|      West|\n",
      "|        394|     26.04|            Other|   0|     false|   Unknown|\n",
      "|        114|     -64.0|      Gas Station|   0|     false|      West|\n",
      "+-----------+----------+-----------------+----+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add basic features\n",
    "print(\"ðŸ”§ Adding basic features...\")\n",
    "\n",
    "# First, ensure amount is properly numeric - convert to amount_usd as double\n",
    "df = df.withColumn(\"amount_usd\", regexp_replace(col(\"amount\"), \"[$]\", \"\").cast(\"double\"))\n",
    "\n",
    "print(f\"âœ… Amount data types - USD: {dict(df.dtypes)['amount_usd']}\")\n",
    "\n",
    "# Add simple time features\n",
    "df = df.withColumn(\"hour\", hour(col(\"transaction_date\"))) \\\n",
    "       .withColumn(\"is_weekend\", dayofweek(col(\"transaction_date\")).isin([1, 7]))\n",
    "\n",
    "# Add merchant category (simplified)\n",
    "df = df.withColumn(\"merchant_category\",\n",
    "                   when(col(\"mcc\").isin(5411, 5441), \"Grocery\")\n",
    "                   .when(col(\"mcc\").isin(5812, 5813), \"Restaurant\") \n",
    "                   .when(col(\"mcc\").isin(5541, 5542), \"Gas Station\")\n",
    "                   .otherwise(\"Other\"))\n",
    "\n",
    "# Add zip_region column\n",
    "df = df.withColumn(\"zip_region\",\n",
    "                   when(col(\"zip\").substr(1,1).isin([\"0\", \"1\", \"2\"]), \"Northeast\")\n",
    "                   .when(col(\"zip\").substr(1,1).isin([\"3\", \"4\", \"5\"]), \"Southeast\") \n",
    "                   .when(col(\"zip\").substr(1,1).isin([\"6\", \"7\"]), \"Central\")\n",
    "                   .when(col(\"zip\").substr(1,1).isin([\"8\", \"9\"]), \"West\")\n",
    "                   .otherwise(\"Unknown\"))\n",
    "\n",
    "# Create temp view for SQL\n",
    "df.createOrReplaceTempView(\"transactions\")\n",
    "print(\"âœ… Features added and temp view created!\")\n",
    "\n",
    "# Show sample with numeric amounts\n",
    "df.select(\"customer_id\", \"amount_usd\", \"merchant_category\", \"hour\", \"is_weekend\", \"zip_region\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9609b4d",
   "metadata": {},
   "source": [
    "## 2. Basic Data Exploration with Spark ðŸ¼âž¡ï¸ðŸ”¥\n",
    "**Goal:** Explore the 1GB+ dataset with Spark (no pandas copies)\n",
    "\n",
    "### ðŸŽ“ Live Coding Exercise:\n",
    "- **Instructor:** Demonstrates Spark actions and SQL\n",
    "- **Students:** Build aggregations and quality checks at scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d2f757ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š BANKING DATA OVERVIEW (Spark)\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 13,305,915\n",
      "root\n",
      " |-- transaction_id: integer (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- card_id: integer (nullable = true)\n",
      " |-- amount: string (nullable = true)\n",
      " |-- use_chip: string (nullable = true)\n",
      " |-- merchant_id: integer (nullable = true)\n",
      " |-- merchant_city: string (nullable = true)\n",
      " |-- merchant_state: string (nullable = true)\n",
      " |-- zip: double (nullable = true)\n",
      " |-- mcc: integer (nullable = true)\n",
      " |-- errors: string (nullable = true)\n",
      " |-- transaction_date: timestamp (nullable = true)\n",
      " |-- amount_usd: double (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- is_weekend: boolean (nullable = true)\n",
      " |-- merchant_category: string (nullable = false)\n",
      " |-- zip_region: string (nullable = false)\n",
      "\n",
      "\n",
      "ðŸ“… Date range:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n",
      "|           min_date|           max_date|\n",
      "+-------------------+-------------------+\n",
      "|2010-01-01 00:01:00|2019-10-31 23:59:00|\n",
      "+-------------------+-------------------+\n",
      "\n",
      "\n",
      "ðŸ“† Transactions by weekday:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|weekday|  count|\n",
      "+-------+-------+\n",
      "|    Fri|1895372|\n",
      "|    Mon|1896914|\n",
      "|    Sat|1902370|\n",
      "|    Sun|1899044|\n",
      "|    Thu|1918666|\n",
      "|    Tue|1897678|\n",
      "|    Wed|1895871|\n",
      "+-------+-------+\n",
      "\n",
      "\n",
      "ðŸ‘¥ Unique customers:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|unique_customers|\n",
      "+----------------+\n",
      "|            1219|\n",
      "+----------------+\n",
      "\n",
      "\n",
      "ðŸ’° Amount stats:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+---------+------+-------+\n",
      "|n       |avg |quantiles|min   |max    |\n",
      "+--------+----+---------+------+-------+\n",
      "|13305915|NULL|NULL     |$-0.00|$999.97|\n",
      "+--------+----+---------+------+-------+\n",
      "\n",
      "\n",
      "ðŸª Top merchant IDs:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 765:==================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|merchant_id|count |\n",
      "+-----------+------+\n",
      "|59935      |610053|\n",
      "|27092      |589140|\n",
      "|61195      |562410|\n",
      "|39021      |440281|\n",
      "|43293      |362842|\n",
      "|22204      |347511|\n",
      "|14528      |333505|\n",
      "|60569      |301657|\n",
      "|50783      |298231|\n",
      "|75781      |273351|\n",
      "+-----------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# ðŸ§‘â€ðŸ« INSTRUCTOR: Basic Spark exploration (precoded)\n",
    "def explore_banking_data_spark(df):\n",
    "    \"\"\"\n",
    "    Scalable data exploration using Spark\n",
    "    - Schema, counts, ranges, basic distributions\n",
    "    - No driver-side collect() on large datasets\n",
    "    \"\"\"\n",
    "    from pyspark.sql import functions as F\n",
    "    \n",
    "    print(\"ðŸ“Š BANKING DATA OVERVIEW (Spark)\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(f\"Total rows: {df.count():,}\")\n",
    "    df.printSchema()\n",
    "    \n",
    "    # Columns we expect (best effort)\n",
    "    available_cols = set([c.lower() for c in df.columns])\n",
    "    \n",
    "    if \"transaction_date\" in available_cols:\n",
    "        print(\"\\nðŸ“… Date range:\")\n",
    "        df.select(F.min(\"transaction_date\").alias(\"min_date\"), F.max(\"transaction_date\").alias(\"max_date\")).show()\n",
    "        \n",
    "        print(\"\\nðŸ“† Transactions by weekday:\")\n",
    "        df.withColumn(\"weekday\", F.date_format(F.col(\"transaction_date\"), \"E\")).groupBy(\"weekday\").count().orderBy(\"weekday\").show()\n",
    "    \n",
    "    if \"customer_id\" in available_cols:\n",
    "        print(\"\\nðŸ‘¥ Unique customers:\")\n",
    "        df.select(F.countDistinct(\"customer_id\").alias(\"unique_customers\")).show()\n",
    "    \n",
    "    if \"amount\" in available_cols:\n",
    "        print(\"\\nðŸ’° Amount stats:\")\n",
    "        df.select(\n",
    "            F.count(\"amount\").alias(\"n\"),\n",
    "            F.mean(\"amount\").alias(\"avg\"),\n",
    "            F.expr(\"percentile_approx(amount, array(0.25,0.5,0.75), 10000)\").alias(\"quantiles\"),\n",
    "            F.min(\"amount\").alias(\"min\"),\n",
    "            F.max(\"amount\").alias(\"max\")\n",
    "        ).show(truncate=False)\n",
    "    \n",
    "    if \"merchant_id\" in available_cols:\n",
    "        print(\"\\nðŸª Top merchant IDs:\")\n",
    "        df.groupBy(\"merchant_id\").count().orderBy(F.desc(\"count\")).show(10, truncate=False)\n",
    "\n",
    "# Run the exploration\n",
    "explore_banking_data_spark(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f38f42ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Basic dataset overview:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total transactions: 13,305,915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique customers: 1,219\n",
      "\n",
      "ðŸ’° Spending by merchant category:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 777:==================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+-----------------+\n",
      "|merchant_category|  total_spending_usd|transaction_count|\n",
      "+-----------------+--------------------+-----------------+\n",
      "|            Other| 4.686805615000004E8|          9040312|\n",
      "|          Grocery| 4.097075415000012E7|          1592584|\n",
      "|       Restaurant| 3.261377996999998E7|          1248308|\n",
      "|      Gas Station|2.9570426660000026E7|          1424711|\n",
      "+-----------------+--------------------+-----------------+\n",
      "\n",
      "âœ… Basic exploration complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Basic data exploration\n",
    "print(\"ðŸ“Š Basic dataset overview:\")\n",
    "print(f\"Total transactions: {df.count():,}\")\n",
    "print(f\"Unique customers: {df.select('customer_id').distinct().count():,}\")\n",
    "\n",
    "# Simple aggregations using numeric amount columns\n",
    "print(\"\\nðŸ’° Spending by merchant category:\")\n",
    "df.groupBy(\"merchant_category\") \\\n",
    "  .agg(sum(\"amount_usd\").alias(\"total_spending_usd\"),\n",
    "       count(\"*\").alias(\"transaction_count\")) \\\n",
    "  .orderBy(desc(\"total_spending_usd\")) \\\n",
    "  .show()\n",
    "\n",
    "print(\"âœ… Basic exploration complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29205fbb",
   "metadata": {},
   "source": [
    "## 3. Spark Session Recap ðŸš€\n",
    "Spark is already initialized. Weâ€™ll keep this short and move to SQL analytics.\n",
    "\n",
    "- Session tuned for local development and large CSVs\n",
    "- Temp view `banking_transactions` is ready\n",
    "- Proceed to analytics at scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "649b9020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â„¹ï¸ Spark utilities available. Session already created above.\n"
     ]
    }
   ],
   "source": [
    "# (Optional) Spark utilities\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "print(\"â„¹ï¸ Spark utilities available. Session already created above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1792d1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Basic Spark operations:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|       amount_usd|\n",
      "+-------+-----------------+\n",
      "|  count|         13305915|\n",
      "|   mean|42.97603902324682|\n",
      "| stddev|81.65574765375871|\n",
      "|    min|           -500.0|\n",
      "|    max|           6820.2|\n",
      "+-------+-----------------+\n",
      "\n",
      "ðŸ“… Weekend vs Weekday spending:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 783:==================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+----------------+\n",
      "|is_weekend|transaction_count|total_amount_usd|\n",
      "+----------+-----------------+----------------+\n",
      "|      true|          3801414|  1.6384547355E8|\n",
      "|     false|          9504501|  4.0799004873E8|\n",
      "+----------+-----------------+----------------+\n",
      "\n",
      "âœ… Basic operations complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Simple Spark DataFrame operations\n",
    "print(\"ðŸ”§ Basic Spark operations:\")\n",
    "\n",
    "# Show dataset info for numeric columns\n",
    "df.select(\"amount_usd\").describe().show()\n",
    "\n",
    "# Weekend vs weekday analysis using SQL with numeric amounts\n",
    "print(\"ðŸ“… Weekend vs Weekday spending:\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    is_weekend,\n",
    "    COUNT(*) as transaction_count,\n",
    "    ROUND(SUM(amount_usd), 2) as total_amount_usd\n",
    "FROM transactions \n",
    "GROUP BY is_weekend\n",
    "\"\"\").show()\n",
    "\n",
    "print(\"âœ… Basic operations complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1092b80a",
   "metadata": {},
   "source": [
    "## 4. Advanced Spark SQL Analytics ðŸ”\n",
    "**Goal:** Complex banking analytics using SQL on big data\n",
    "\n",
    "### ðŸ¦ Real Banking Use Cases:\n",
    "- **Fraud Detection:** Unusual spending patterns\n",
    "- **Customer Segmentation:** Spending behavior analysis\n",
    "- **Risk Assessment:** Transaction pattern analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d1292fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” SIMPLE BANKING ANALYTICS\n",
      "ðŸ‘‘ TOP 3 CUSTOMERS BY SPENDING:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+\n",
      "|customer_id|total_spent_usd|\n",
      "+-----------+---------------+\n",
      "|         96|     2445773.25|\n",
      "|       1686|      2167880.9|\n",
      "|       1340|     2039921.23|\n",
      "+-----------+---------------+\n",
      "\n",
      "ðŸª TOP 3 MERCHANTS BY TRANSACTIONS:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 789:==================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+-----------------+\n",
      "|merchant_id|transaction_count|total_revenue_usd|\n",
      "+-----------+-----------------+-----------------+\n",
      "|      59935|           610053|       8937586.07|\n",
      "|      27092|           589140|    5.315851564E7|\n",
      "|      61195|           562410|    1.201308365E7|\n",
      "+-----------+-----------------+-----------------+\n",
      "\n",
      "âœ… Simple analytics complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# ðŸ§‘â€ðŸ« INSTRUCTOR: Simple banking analytics demo\n",
    "print(\"ðŸ” SIMPLE BANKING ANALYTICS\")\n",
    "\n",
    "# Top customers using numeric amounts\n",
    "print(\"ðŸ‘‘ TOP 3 CUSTOMERS BY SPENDING:\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT customer_id, \n",
    "       ROUND(SUM(amount_usd), 2) as total_spent_usd\n",
    "FROM transactions \n",
    "GROUP BY customer_id \n",
    "ORDER BY total_spent_usd DESC \n",
    "LIMIT 3\n",
    "\"\"\").show()\n",
    "\n",
    "# Simple merchant analysis\n",
    "print(\"ðŸª TOP 3 MERCHANTS BY TRANSACTIONS:\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT merchant_id, \n",
    "       COUNT(*) as transaction_count,\n",
    "       ROUND(SUM(amount_usd), 2) as total_revenue_usd\n",
    "FROM transactions \n",
    "GROUP BY merchant_id \n",
    "ORDER BY transaction_count DESC \n",
    "LIMIT 3\n",
    "\"\"\").show()\n",
    "\n",
    "print(\"âœ… Simple analytics complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d106fcbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš¨ BASIC FRAUD DETECTION\n",
      "ðŸ’° Transactions above $200:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-----------+\n",
      "|customer_id|amount_usd|merchant_id|\n",
      "+-----------+----------+-----------+\n",
      "|        708|    6820.2|      34524|\n",
      "|       1081|   6613.44|       9026|\n",
      "|       1259|   5913.37|      85983|\n",
      "|       1487|   5813.78|       9026|\n",
      "|        278|   5696.78|       7202|\n",
      "+-----------+----------+-----------+\n",
      "\n",
      "âœ… Basic fraud detection complete!\n",
      "ðŸš¨ POTENTIAL FRAUD DETECTION:\n",
      "Find customers with transactions > 3 standard deviations from their average\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 798:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+------------+----------+\n",
      "|risk_level|transaction_count|total_amount|avg_amount|\n",
      "+----------+-----------------+------------+----------+\n",
      "|    NORMAL|         13305915|        NULL|      NULL|\n",
      "+----------+-----------------+------------+----------+\n",
      "\n",
      "âœ… Basic fraud detection complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Simple fraud detection demo\n",
    "print(\"ðŸš¨ BASIC FRAUD DETECTION\")\n",
    "\n",
    "# High amount transactions (potential fraud) using numeric amounts\n",
    "print(\"ðŸ’° Transactions above $200:\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT customer_id, \n",
    "       ROUND(amount_usd, 2) as amount_usd,\n",
    "       merchant_id\n",
    "FROM transactions \n",
    "WHERE amount_usd > 200\n",
    "ORDER BY amount_usd DESC\n",
    "LIMIT 5\n",
    "\"\"\").show()\n",
    "\n",
    "print(\"âœ… Basic fraud detection complete!\")\n",
    "print(\"ðŸš¨ POTENTIAL FRAUD DETECTION:\")\n",
    "print(\"Find customers with transactions > 3 standard deviations from their average\")\n",
    "\n",
    "fraud_query = \"\"\"\n",
    "WITH customer_stats AS (\n",
    "    SELECT \n",
    "        customer_id,\n",
    "        transaction_date,\n",
    "        amount,\n",
    "        AVG(amount) OVER (PARTITION BY customer_id) as avg_amount,\n",
    "        STDDEV_POP(amount) OVER (PARTITION BY customer_id) as stddev_amount\n",
    "    FROM banking_transactions\n",
    "),\n",
    "potential_fraud AS (\n",
    "    SELECT \n",
    "        customer_id,\n",
    "        transaction_date,\n",
    "        amount,\n",
    "        avg_amount,\n",
    "        stddev_amount,\n",
    "        ABS(amount - avg_amount) as deviation,\n",
    "        CASE \n",
    "            WHEN stddev_amount > 0 AND ABS(amount - avg_amount) > 3 * stddev_amount \n",
    "            THEN 'HIGH_RISK'\n",
    "            WHEN stddev_amount > 0 AND ABS(amount - avg_amount) > 2 * stddev_amount \n",
    "            THEN 'MEDIUM_RISK'\n",
    "            ELSE 'NORMAL'\n",
    "        END as risk_level\n",
    "    FROM customer_stats\n",
    ")\n",
    "SELECT \n",
    "    risk_level, \n",
    "    COUNT(*) as transaction_count,\n",
    "    SUM(amount_usd) as total_amount,\n",
    "    AVG(amount_usd) as avg_amount\n",
    "FROM potential_fraud\n",
    "GROUP BY risk_level\n",
    "ORDER BY risk_level\n",
    "\"\"\"\n",
    "spark.sql(fraud_query).show()\n",
    "print(\"âœ… Basic fraud detection complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6c301f",
   "metadata": {},
   "source": [
    "## 5. Simple Cloud Deployment ðŸŒ¥ï¸\n",
    "**Goal:** Basic overview of deploying to cloud\n",
    "\n",
    "### ðŸŒŸ Why Cloud?\n",
    "- **Scale:** Handle big datasets\n",
    "- **Storage:** Secure data storage  \n",
    "- **Compute:** More processing power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ed3b21eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â˜ï¸ CLOUD DEPLOYMENT BASICS\n",
      "Key concepts:\n",
      "1. Upload data to cloud storage\n",
      "2. Create compute cluster\n",
      "3. Run Spark jobs\n",
      "4. Store results\n",
      "\n",
      "âœ… Cloud overview complete!\n"
     ]
    }
   ],
   "source": [
    "# ðŸ§‘â€ðŸ« INSTRUCTOR: Simple cloud overview (demo only)\n",
    "print(\"â˜ï¸ CLOUD DEPLOYMENT BASICS\")\n",
    "print(\"Key concepts:\")\n",
    "print(\"1. Upload data to cloud storage\")\n",
    "print(\"2. Create compute cluster\") \n",
    "print(\"3. Run Spark jobs\")\n",
    "print(\"4. Store results\")\n",
    "\n",
    "print(\"\\nâœ… Cloud overview complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "91f6ea5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ COMPLETE: Customize the deployment configuration!\n",
      "==================================================\n",
      "âš™ï¸ CUSTOMIZE YOUR CONFIGURATION:\n",
      "ðŸ“ Your GCP Config:\n",
      "{\n",
      "  \"project_id\": \"banking-analytics-demo-2025\",\n",
      "  \"bucket_name\": \"banking-data-workshop-eu\",\n",
      "  \"region\": \"europe-west3\",\n",
      "  \"dataset_location\": \"EU\",\n",
      "  \"service_account_email\": \"banking-analytics@banking-analytics-demo-2025.iam.gserviceaccount.com\",\n",
      "  \"vpc_network\": \"banking-vpc\",\n",
      "  \"subnet\": \"banking-subnet-eu-west3\"\n",
      "}\n",
      "\n",
      "âœ… DEPLOYMENT CHECKLIST:\n",
      "\n",
      "âœ… Cloud overview complete!\n"
     ]
    }
   ],
   "source": [
    "# âœ… COMPLETE SOLUTION: Customize GCP deployment\n",
    "print(\"ðŸŽ¯ COMPLETE: Customize the deployment configuration!\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Solution 1: Update configuration for your environment\n",
    "print(\"âš™ï¸ CUSTOMIZE YOUR CONFIGURATION:\")\n",
    "my_gcp_config = {\n",
    "    \"project_id\": \"banking-analytics-demo-2025\",  # Example project ID\n",
    "    \"bucket_name\": \"banking-data-workshop-eu\",   # Example bucket name\n",
    "    \"region\": \"europe-west3\",                    # Frankfurt region for GDPR compliance\n",
    "    \"dataset_location\": \"EU\",                    # European Union for data residency\n",
    "    \"service_account_email\": \"banking-analytics@banking-analytics-demo-2025.iam.gserviceaccount.com\",\n",
    "    \"vpc_network\": \"banking-vpc\",                # Custom VPC for security\n",
    "    \"subnet\": \"banking-subnet-eu-west3\"          # Specific subnet\n",
    "}\n",
    "\n",
    "print(\"ðŸ“ Your GCP Config:\")\n",
    "import json\n",
    "print(json.dumps(my_gcp_config, indent=2))\n",
    "\n",
    "# Solution 2: Create a deployment checklist\n",
    "print(\"\\nâœ… DEPLOYMENT CHECKLIST:\")\n",
    "deployment_checklist = [\n",
    "    \"GCP project created and billing enabled\",\n",
    "    \"Service account created with necessary permissions\",\n",
    "    \"Cloud Storage bucket created in EU region\",\n",
    "    \"Databricks workspace provisioned\"\n",
    "]\n",
    "print(\"\\nâœ… Cloud overview complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc056ce1",
   "metadata": {},
   "source": [
    "## 6. Simple Data Integration ðŸ”—\n",
    "**Goal:** Combine banking data with external sources\n",
    "\n",
    "### ðŸ’¡ Real Banking Examples:\n",
    "- **Exchange Rates:** Convert international transactions\n",
    "- **Interest Rates:** Economic impact on spending\n",
    "- **Merchant Data:** Enhanced merchant information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cd481a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”— SIMPLE API INTEGRATION\n",
      "ðŸ“Š Fetching live exchange rates...\n",
      "âœ… API call successful!\n",
      "ðŸ“… Date: 2025-08-10\n",
      "ðŸ’± Base: EUR\n",
      "\n",
      "ðŸ’° Today's rates:\n",
      "EUR â†’ USD: 1.164821\n",
      "EUR â†’ GBP: 0.867295\n",
      "ðŸ”„ Creating EUR amounts using live rates...\n",
      "âœ… Temp view updated with live exchange rates!\n",
      "\n",
      "ðŸ’¡ Sample transactions with live exchange rates:\n",
      "+-----------+----------+----------+-----------------+\n",
      "|customer_id|amount_usd|amount_eur|merchant_category|\n",
      "+-----------+----------+----------+-----------------+\n",
      "|       1556|     -77.0|     -66.1|            Other|\n",
      "|        561|     14.57|     12.51|            Other|\n",
      "|       1129|      80.0|     68.68|            Other|\n",
      "|        430|     200.0|     171.7|            Other|\n",
      "|        848|     46.41|     39.84|       Restaurant|\n",
      "+-----------+----------+----------+-----------------+\n",
      "\n",
      "âœ… Simple live integration complete!\n",
      "âœ… API call successful!\n",
      "ðŸ“… Date: 2025-08-10\n",
      "ðŸ’± Base: EUR\n",
      "\n",
      "ðŸ’° Today's rates:\n",
      "EUR â†’ USD: 1.164821\n",
      "EUR â†’ GBP: 0.867295\n",
      "ðŸ”„ Creating EUR amounts using live rates...\n",
      "âœ… Temp view updated with live exchange rates!\n",
      "\n",
      "ðŸ’¡ Sample transactions with live exchange rates:\n",
      "+-----------+----------+----------+-----------------+\n",
      "|customer_id|amount_usd|amount_eur|merchant_category|\n",
      "+-----------+----------+----------+-----------------+\n",
      "|       1556|     -77.0|     -66.1|            Other|\n",
      "|        561|     14.57|     12.51|            Other|\n",
      "|       1129|      80.0|     68.68|            Other|\n",
      "|        430|     200.0|     171.7|            Other|\n",
      "|        848|     46.41|     39.84|       Restaurant|\n",
      "+-----------+----------+----------+-----------------+\n",
      "\n",
      "âœ… Simple live integration complete!\n"
     ]
    }
   ],
   "source": [
    "# ðŸ§‘â€ðŸ« INSTRUCTOR: Simple API integration for live exchange rates\n",
    "print(\"ðŸ”— SIMPLE API INTEGRATION\")\n",
    "\n",
    "# Get live exchange rates\n",
    "print(\"ðŸ“Š Fetching live exchange rates...\")\n",
    "import requests\n",
    "\n",
    "# Simple API call\n",
    "api_url = \"https://api.exchangeratesapi.io/v1/latest?access_key=24da234d4ded987472b5ece3b4981c9b&format=1\"\n",
    "\n",
    "try:\n",
    "    response = requests.get(api_url)\n",
    "    data = response.json()\n",
    "\n",
    "    if data.get('success'):\n",
    "        print(\"âœ… API call successful!\")\n",
    "        print(f\"ðŸ“… Date: {data['date']}\")\n",
    "        print(f\"ðŸ’± Base: {data['base']}\")\n",
    "        \n",
    "        # Get key rates we need\n",
    "        usd_rate = data['rates']['USD']\n",
    "        gbp_rate = data['rates']['GBP']\n",
    "        \n",
    "        print(f\"\\nðŸ’° Today's rates:\")\n",
    "        print(f\"EUR â†’ USD: {usd_rate}\")\n",
    "        print(f\"EUR â†’ GBP: {gbp_rate}\")\n",
    "        \n",
    "        # Create EUR column from USD using live rate\n",
    "        print(\"ðŸ”„ Creating EUR amounts using live rates...\")\n",
    "        df = df.withColumn(\"amount_eur\", col(\"amount_usd\") / usd_rate)\n",
    "        \n",
    "        # Recreate temp view with updated data\n",
    "        df.createOrReplaceTempView(\"transactions\")\n",
    "        print(\"âœ… Temp view updated with live exchange rates!\")\n",
    "        \n",
    "    else:\n",
    "        print(\"ðŸ”„ Using fallback rates...\")\n",
    "        usd_rate = 1.16\n",
    "        gbp_rate = 0.87\n",
    "        df = df.withColumn(\"amount_eur\", col(\"amount_usd\") / usd_rate)\n",
    "        df.createOrReplaceTempView(\"transactions\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"ðŸš¨ Error: {e}\")\n",
    "    print(\"ðŸ”„ Using fallback rates...\")\n",
    "    usd_rate = 1.16\n",
    "    gbp_rate = 0.87\n",
    "    df = df.withColumn(\"amount_eur\", col(\"amount_usd\") / usd_rate)\n",
    "    df.createOrReplaceTempView(\"transactions\")\n",
    "\n",
    "# Simple live currency conversion example\n",
    "print(\"\\nðŸ’¡ Sample transactions with live exchange rates:\")\n",
    "conversion_query = \"\"\"\n",
    "SELECT \n",
    "    customer_id,\n",
    "    ROUND(amount_usd, 2) as amount_usd,\n",
    "    ROUND(amount_eur, 2) as amount_eur,\n",
    "    merchant_category\n",
    "FROM transactions \n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(conversion_query).show()\n",
    "\n",
    "print(\"âœ… Simple live integration complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c24d8bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š LIVE EXCHANGE RATE ANALYSIS\n",
      "ðŸ’¡ Let's analyze our banking data using LIVE exchange rates from the API!\n",
      "Business question: How do live currency fluctuations affect spending patterns?\n",
      "\n",
      "ðŸ” Analysis using LIVE rate: 1 EUR = 1.164821 USD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+--------------+--------------+------------------+-------+-------+\n",
      "|merchant_category|transactions|     total_usd|     total_eur|usd_eur_difference|avg_usd|avg_eur|\n",
      "+-----------------+------------+--------------+--------------+------------------+-------+-------+\n",
      "|            Other|     3469683|4.0457538372E8|3.4732837382E8|      5.72470099E7|  116.6|  100.1|\n",
      "|      Gas Station|      509646| 4.101957026E7| 3.521534232E7|        5804227.94|  80.49|   69.1|\n",
      "|          Grocery|      259596| 2.451713686E7| 2.104798665E7|        3469150.21|  94.44|  81.08|\n",
      "|       Restaurant|      208070| 1.465861958E7| 1.258443965E7|        2074179.93|  70.45|  60.48|\n",
      "+-----------------+------------+--------------+--------------+------------------+-------+-------+\n",
      "\n",
      "\n",
      "ðŸ“ˆ CURRENCY IMPACT ANALYSIS (Live Rate: 1.164821):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 807:==================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------------+-----------------------+-----------------------+\n",
      "|merchant_category|avg_usd_per_transaction|avg_eur_per_transaction|currency_impact_percent|\n",
      "+-----------------+-----------------------+-----------------------+-----------------------+\n",
      "|          Grocery|                  63.69|                  54.68|                  16.48|\n",
      "|            Other|                  81.58|                  70.04|                  16.48|\n",
      "|      Gas Station|                  68.39|                  58.71|                  16.48|\n",
      "|       Restaurant|                  47.26|                  40.58|                  16.48|\n",
      "+-----------------+-----------------------+-----------------------+-----------------------+\n",
      "\n",
      "\n",
      "ðŸ’¡ LIVE EXCHANGE RATE INSIGHTS:\n",
      "â€¢ Today's EURâ†’USD rate: 1.164821\n",
      "â€¢ 'USD-EUR Difference' shows currency conversion impact\n",
      "â€¢ 'Currency Impact %' shows relative cost difference for EUR vs USD customers\n",
      "â€¢ Higher impact % = more expensive for EUR-based customers\n",
      "â€¢ This analysis updates with LIVE market rates!\n",
      "âœ… Live exchange rate analysis complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Integration analysis using live exchange rates\n",
    "print(\"ðŸ“Š LIVE EXCHANGE RATE ANALYSIS\")\n",
    "\n",
    "print(\"ðŸ’¡ Let's analyze our banking data using LIVE exchange rates from the API!\")\n",
    "print(\"Business question: How do live currency fluctuations affect spending patterns?\")\n",
    "\n",
    "# Analysis using live EUR/USD conversion\n",
    "print(f\"\\nðŸ” Analysis using LIVE rate: 1 EUR = {usd_rate} USD\")\n",
    "\n",
    "live_rate_analysis = \"\"\"\n",
    "SELECT \n",
    "    merchant_category,\n",
    "    COUNT(*) as transactions,\n",
    "    ROUND(SUM(amount_usd), 2) as total_usd,\n",
    "    ROUND(SUM(amount_eur), 2) as total_eur,\n",
    "    ROUND(SUM(amount_usd) - SUM(amount_eur), 2) as usd_eur_difference,\n",
    "    ROUND(AVG(amount_usd), 2) as avg_usd,\n",
    "    ROUND(AVG(amount_eur), 2) as avg_eur\n",
    "FROM transactions \n",
    "WHERE amount_usd > 50\n",
    "GROUP BY merchant_category\n",
    "ORDER BY total_usd DESC\n",
    "\"\"\"\n",
    "\n",
    "result = spark.sql(live_rate_analysis)\n",
    "result.show()\n",
    "\n",
    "# Advanced analysis: Currency impact by spending category\n",
    "print(f\"\\nðŸ“ˆ CURRENCY IMPACT ANALYSIS (Live Rate: {usd_rate}):\")\n",
    "\n",
    "currency_impact_query = \"\"\"\n",
    "SELECT \n",
    "    merchant_category,\n",
    "    ROUND(AVG(amount_usd), 2) as avg_usd_per_transaction,\n",
    "    ROUND(AVG(amount_eur), 2) as avg_eur_per_transaction,\n",
    "    ROUND((AVG(amount_usd) - AVG(amount_eur)) / AVG(amount_eur) * 100, 2) as currency_impact_percent\n",
    "FROM transactions \n",
    "WHERE amount_usd > 20\n",
    "GROUP BY merchant_category\n",
    "ORDER BY currency_impact_percent DESC\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(currency_impact_query).show()\n",
    "\n",
    "# Business insights with live data\n",
    "print(\"\\nðŸ’¡ LIVE EXCHANGE RATE INSIGHTS:\")\n",
    "print(f\"â€¢ Today's EURâ†’USD rate: {usd_rate}\")\n",
    "print(\"â€¢ 'USD-EUR Difference' shows currency conversion impact\")\n",
    "print(\"â€¢ 'Currency Impact %' shows relative cost difference for EUR vs USD customers\") \n",
    "print(\"â€¢ Higher impact % = more expensive for EUR-based customers\")\n",
    "print(\"â€¢ This analysis updates with LIVE market rates!\")\n",
    "\n",
    "print(\"âœ… Live exchange rate analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f38621",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Workshop Summary\n",
    "\n",
    "You've learned the essentials of big data analytics:\n",
    "\n",
    "1. **PySpark Basics:** Loading and processing data\n",
    "2. **SQL Analysis:** Simple aggregations and insights\n",
    "3. **Banking Analytics:** Basic fraud detection\n",
    "4. **Cloud Concepts:** Deployment overview"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
