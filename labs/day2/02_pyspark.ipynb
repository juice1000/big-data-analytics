{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Day 2: Advanced Analytics & Machine Learning with PySpark\n",
        "\n",
        "**Workshop Schedule:**\n",
        "- 13:00-13:45: Regressionsanalyse mit PySpark ML\n",
        "- 13:55-14:40: Unstructured Data Analytics mit Spark NLP  \n",
        "- 14:50-15:40: Big Data Visualization & Spark DataFrame Deep-Dive\n",
        "\n",
        "## Dataset Overview\n",
        "\n",
        "We'll be working with the **full 13M+ transactions dataset** using PySpark:\n",
        "- **13M+ transaction records** (no sampling needed!)\n",
        "- **Fields:** id, date, client_id, card_id, amount, use_chip, merchant_id, merchant_city, merchant_state, zip, mcc, errors\n",
        "- **Time Range:** 2010+ banking transactions\n",
        "- **Use Cases:** Scalable fraud detection, customer analytics, risk scoring\n",
        "- **Processing:** Distributed computing with Apache Spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import PySpark and related libraries\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.ml.feature import VectorAssembler, StandardScaler, StringIndexer, OneHotEncoder\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.classification import LogisticRegression as SparkLogisticRegression\n",
        "from pyspark.ml.evaluation import RegressionEvaluator, BinaryClassificationEvaluator\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "# Traditional ML and visualization (for model evaluation)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spark Version: 3.5.3\n",
            "Available cores: 8\n"
          ]
        }
      ],
      "source": [
        "# Initialize Spark Session with optimized configuration\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"BankingAnalytics\") \\\n",
        "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
        "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
        "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
        "    .config(\"spark.driver.memory\", \"4g\") \\\n",
        "    .config(\"spark.executor.memory\", \"4g\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Set log level to reduce verbose output\n",
        "spark.sparkContext.setLogLevel(\"WARN\")\n",
        "\n",
        "print(f\"Spark Version: {spark.version}\")\n",
        "print(f\"Available cores: {spark.sparkContext.defaultParallelism}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading full 13M+ transaction dataset...\n",
            "Dataset loaded successfully!\n",
            "Total rows: 13,305,915\n",
            "Number of partitions: 10\n",
            "root\n",
            " |-- id: integer (nullable = true)\n",
            " |-- date: timestamp (nullable = true)\n",
            " |-- client_id: integer (nullable = true)\n",
            " |-- card_id: integer (nullable = true)\n",
            " |-- amount: string (nullable = true)\n",
            " |-- use_chip: string (nullable = true)\n",
            " |-- merchant_id: integer (nullable = true)\n",
            " |-- merchant_city: string (nullable = true)\n",
            " |-- merchant_state: string (nullable = true)\n",
            " |-- zip: double (nullable = true)\n",
            " |-- mcc: integer (nullable = true)\n",
            " |-- errors: string (nullable = true)\n",
            "\n",
            "+-------+-------------------+---------+-------+-------+-----------------+-----------+-------------+--------------+-------+----+------+\n",
            "|     id|               date|client_id|card_id| amount|         use_chip|merchant_id|merchant_city|merchant_state|    zip| mcc|errors|\n",
            "+-------+-------------------+---------+-------+-------+-----------------+-----------+-------------+--------------+-------+----+------+\n",
            "|7475327|2010-01-01 00:01:00|     1556|   2972|$-77.00|Swipe Transaction|      59935|       Beulah|            ND|58523.0|5499|  NULL|\n",
            "|7475328|2010-01-01 00:02:00|      561|   4575| $14.57|Swipe Transaction|      67570|   Bettendorf|            IA|52722.0|5311|  NULL|\n",
            "|7475329|2010-01-01 00:02:00|     1129|    102| $80.00|Swipe Transaction|      27092|        Vista|            CA|92084.0|4829|  NULL|\n",
            "|7475331|2010-01-01 00:05:00|      430|   2860|$200.00|Swipe Transaction|      27092|  Crown Point|            IN|46307.0|4829|  NULL|\n",
            "|7475332|2010-01-01 00:06:00|      848|   3915| $46.41|Swipe Transaction|      13051|      Harwood|            MD|20776.0|5813|  NULL|\n",
            "+-------+-------------------+---------+-------+-------+-----------------+-----------+-------------+--------------+-------+----+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25/08/10 21:45:06 WARN CacheManager: Asked to cache already cached data.\n"
          ]
        }
      ],
      "source": [
        "# Load the FULL dataset with PySpark (no sampling!)\n",
        "print(\"Loading full 13M+ transaction dataset...\")\n",
        "\n",
        "# Define schema for better performance\n",
        "schema = StructType([\n",
        "    StructField(\"id\", IntegerType(), True),\n",
        "    StructField(\"date\", TimestampType(), True),\n",
        "    StructField(\"client_id\", IntegerType(), True),\n",
        "    StructField(\"card_id\", IntegerType(), True),\n",
        "    StructField(\"amount\", StringType(), True),\n",
        "    StructField(\"use_chip\", StringType(), True),\n",
        "    StructField(\"merchant_id\", IntegerType(), True),\n",
        "    StructField(\"merchant_city\", StringType(), True),\n",
        "    StructField(\"merchant_state\", StringType(), True),\n",
        "    StructField(\"zip\", DoubleType(), True),\n",
        "    StructField(\"mcc\", IntegerType(), True),\n",
        "    StructField(\"errors\", StringType(), True)\n",
        "])\n",
        "\n",
        "# Load data with optimized settings\n",
        "df_spark = spark.read.csv(\n",
        "    \"../data/transactions_data.csv\",\n",
        "    header=True,\n",
        "    schema=schema,\n",
        "    timestampFormat=\"yyyy-MM-dd HH:mm:ss\"\n",
        ")\n",
        "\n",
        "# Cache the DataFrame for better performance\n",
        "df_spark.cache()\n",
        "\n",
        "print(f\"Dataset loaded successfully!\")\n",
        "print(f\"Total rows: {df_spark.count():,}\")\n",
        "print(f\"Number of partitions: {df_spark.rdd.getNumPartitions()}\")\n",
        "\n",
        "df_spark.printSchema()\n",
        "df_spark.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# 📊 13:00-13:45: Regressionsanalyse mit PySpark ML\n",
        "\n",
        "## 🎯 Lernziele:\n",
        "- Distributed Linear Regression für Customer Lifetime Value\n",
        "- Scalable Logistic Regression für Fraud Detection\n",
        "- PySpark ML Pipeline für Credit Risk Scoring\n",
        "- Big Data Model Evaluation Metriken"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Distributed Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25/08/10 21:45:12 WARN CacheManager: Asked to cache already cached data.        \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distributed preprocessing completed!\n",
            "Processed records: 12,635,227\n",
            "Fraud rate: 0.5%\n",
            "+-------+--------------+---------+----------+----+--------+\n",
            "| amount|amount_numeric|is_online|is_weekend|hour|is_fraud|\n",
            "+-------+--------------+---------+----------+----+--------+\n",
            "| $14.57|         14.57|        0|         0|   0|       0|\n",
            "| $80.00|          80.0|        0|         0|   0|       0|\n",
            "|$200.00|         200.0|        0|         0|   0|       0|\n",
            "| $46.41|         46.41|        0|         0|   0|       0|\n",
            "|  $4.81|          4.81|        0|         0|   0|       0|\n",
            "+-------+--------------+---------+----------+----+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Advanced preprocessing with Spark SQL functions\n",
        "df_processed = df_spark \\\n",
        "    .withColumn(\"amount_numeric\", regexp_replace(col(\"amount\"), \"[\\$,]\", \"\").cast(\"double\")) \\\n",
        "    .withColumn(\"is_online\", (col(\"merchant_city\") == \"ONLINE\").cast(\"int\")) \\\n",
        "    .withColumn(\"is_weekend\", dayofweek(col(\"date\")).isin([1, 7]).cast(\"int\")) \\\n",
        "    .withColumn(\"hour\", hour(col(\"date\"))) \\\n",
        "    .withColumn(\"month\", month(col(\"date\"))) \\\n",
        "    .withColumn(\"weekday\", date_format(col(\"date\"), \"EEEE\")) \\\n",
        "    .withColumn(\"year\", year(col(\"date\"))) \\\n",
        "    .filter(col(\"amount_numeric\").isNotNull() & (col(\"amount_numeric\") > 0))\n",
        "\n",
        "# Add fraud indicators using distributed computing\n",
        "amount_95th = df_processed.approxQuantile(\"amount_numeric\", [0.95], 0.01)[0]\n",
        "\n",
        "df_processed = df_processed \\\n",
        "    .withColumn(\"unusual_amount\", (col(\"amount_numeric\") > amount_95th).cast(\"int\")) \\\n",
        "    .withColumn(\"night_transaction\", ((col(\"hour\") < 6) | (col(\"hour\") > 22)).cast(\"int\")) \\\n",
        "    .withColumn(\"round_amount\", (col(\"amount_numeric\") % 10 == 0).cast(\"int\"))\n",
        "\n",
        "# Create synthetic fraud labels (distributed random generation)\n",
        "from pyspark.sql.functions import rand\n",
        "\n",
        "df_processed = df_processed \\\n",
        "    .withColumn(\"fraud_probability\", \n",
        "                col(\"unusual_amount\") * 0.3 + \n",
        "                col(\"night_transaction\") * 0.2 + \n",
        "                col(\"is_online\") * 0.1 + \n",
        "                col(\"round_amount\") * 0.1) \\\n",
        "    .withColumn(\"is_fraud\", (rand(42) < col(\"fraud_probability\") * 0.1).cast(\"int\"))\n",
        "\n",
        "# Cache the processed DataFrame\n",
        "df_processed.cache()\n",
        "\n",
        "print(\"Distributed preprocessing completed!\")\n",
        "print(f\"Processed records: {df_processed.count():,}\")\n",
        "print(f\"Fraud rate: {df_processed.agg(avg('is_fraud')).collect()[0][0]:.1%}\")\n",
        "\n",
        "df_processed.select(\"amount\", \"amount_numeric\", \"is_online\", \"is_weekend\", \"hour\", \"is_fraud\").show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Distributed Customer Analytics (Linear Regression)\n",
        "\n",
        "### 📝 **EXERCISE 1: Scalable Customer Features**\n",
        "\n",
        "Create customer features using distributed aggregations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing customer features across all 13M+ transactions...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25/08/10 21:45:13 WARN CacheManager: Asked to cache already cached data.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Customer features computed for 1,219 customers\n",
            "+-------+------------------+------------------+------------------+------------------+------------------+--------------------+--------------------+------------------+-----------------+------------------+------------------+--------------------+\n",
            "|summary|         client_id|       total_spend|   avg_transaction| transaction_count|  spend_volatility|        online_ratio|       weekend_ratio|merchant_diversity|  fraud_incidents|       days_active|     spend_per_day|transactions_per_day|\n",
            "+-------+------------------+------------------+------------------+------------------+------------------+--------------------+--------------------+------------------+-----------------+------------------+------------------+--------------------+\n",
            "|  count|              1219|              1219|              1219|              1219|              1219|                1219|                1219|              1219|             1219|              1219|              1219|                1219|\n",
            "|   mean|1004.9163248564397|  524491.029220673| 51.82177875260759|10365.239540607055|  69.7079091701339| 0.10925981081625458| 0.28594125204730075|293.42329778506974|49.49138638228056|3491.9909762100083|149.68886263228157|  2.9548684310549085|\n",
            "| stddev| 582.3844617616658|320692.01206433104|19.187935041076916| 5184.142122237623|27.176290169499875| 0.11710856714887088|0.004849616075312...| 96.65000243520372|41.76905639209353|  361.300352768018| 89.49294842201415|  1.4241933903709993|\n",
            "|    min|                 0|31753.339999999997|5.5917176246772655|               695| 8.596664633604854|0.009397332733104497|  0.2692490720472066|                56|                2|               852|11.459050403787245|  0.1935933147632312|\n",
            "|    max|              1998|        3002117.15|178.00942446043166|             42137| 275.2151673282103|  0.7527998219980716| 0.30886987843313823|               846|              363|              3590| 836.0114592035644|  11.734057365636312|\n",
            "+-------+------------------+------------------+------------------+------------------+------------------+--------------------+--------------------+------------------+-----------------+------------------+------------------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Distributed customer aggregation (handles all 13M records)\n",
        "print(\"Computing customer features across all 13M+ transactions...\")\n",
        "\n",
        "customer_features_spark = df_processed.groupBy(\"client_id\").agg(\n",
        "    sum(\"amount_numeric\").alias(\"total_spend\"),\n",
        "    avg(\"amount_numeric\").alias(\"avg_transaction\"),\n",
        "    count(\"*\").alias(\"transaction_count\"),\n",
        "    stddev(\"amount_numeric\").alias(\"spend_volatility\"),\n",
        "    avg(\"is_online\").alias(\"online_ratio\"),\n",
        "    avg(\"is_weekend\").alias(\"weekend_ratio\"),\n",
        "    countDistinct(\"merchant_id\").alias(\"merchant_diversity\"),\n",
        "    min(\"date\").alias(\"first_transaction\"),\n",
        "    max(\"date\").alias(\"last_transaction\"),\n",
        "    sum(\"is_fraud\").alias(\"fraud_incidents\")\n",
        ").filter(col(\"transaction_count\") >= 5)\n",
        "\n",
        "# Add derived features\n",
        "customer_features_spark = customer_features_spark \\\n",
        "    .withColumn(\"days_active\", \n",
        "                datediff(col(\"last_transaction\"), col(\"first_transaction\"))) \\\n",
        "    .withColumn(\"spend_per_day\", \n",
        "                col(\"total_spend\") / (col(\"days_active\") + 1)) \\\n",
        "    .withColumn(\"transactions_per_day\", \n",
        "                col(\"transaction_count\") / (col(\"days_active\") + 1))\n",
        "\n",
        "customer_features_spark.cache()\n",
        "\n",
        "print(f\"Customer features computed for {customer_features_spark.count():,} customers\")\n",
        "customer_features_spark.describe().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 🔍 **YOUR TASK:** \n",
        "Build distributed linear regression for Customer Lifetime Value:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distributed Linear Regression Model trained on full dataset!\n",
            "+---------+------------------+------------------+\n",
            "|client_id|       total_spend|        prediction|\n",
            "+---------+------------------+------------------+\n",
            "|     1088|         400451.06| 392772.9110877131|\n",
            "|     1959| 492257.1699999999| 707504.7068278526|\n",
            "|      623|423696.08999999997| 540510.4679938685|\n",
            "|     1127|         613557.31| 654705.5409425246|\n",
            "|     1507|241462.71000000002| 184579.5460669197|\n",
            "|     1352|286005.47000000003| 291622.0458235153|\n",
            "|      804| 525850.8300000001| 624147.2969585361|\n",
            "|     1766|177824.36000000002| 120655.8631290571|\n",
            "|      918|         382516.18|368079.39890798414|\n",
            "|     1863|         631116.75| 634763.1893708627|\n",
            "+---------+------------------+------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# TODO: Complete PySpark ML Linear Regression implementation\n",
        "\n",
        "# 1. Prepare features for ML pipeline\n",
        "feature_cols = [\"avg_transaction\", \"transaction_count\", \"merchant_diversity\", \n",
        "                \"online_ratio\", \"weekend_ratio\"]\n",
        "\n",
        "# Fill null values\n",
        "customer_ml = customer_features_spark.fillna(0.0, subset=feature_cols)\n",
        "\n",
        "# 2. Create feature vector using VectorAssembler\n",
        "# YOUR CODE HERE\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
        "\n",
        "# 3. Split data (distributed)\n",
        "# YOUR CODE HERE\n",
        "train_data, test_data = customer_ml.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# 4. Create Linear Regression model\n",
        "# YOUR CODE HERE\n",
        "lr = LinearRegression(featuresCol=\"features\", labelCol=\"total_spend\", \n",
        "                     regParam=0.1, elasticNetParam=0.0)\n",
        "\n",
        "# 5. Create ML Pipeline\n",
        "# YOUR CODE HERE\n",
        "pipeline = Pipeline(stages=[assembler, lr])\n",
        "\n",
        "# 6. Train model on distributed data\n",
        "# YOUR CODE HERE\n",
        "model = pipeline.fit(train_data)\n",
        "\n",
        "# 7. Make predictions\n",
        "# YOUR CODE HERE\n",
        "predictions = model.transform(test_data)\n",
        "\n",
        "print(\"Distributed Linear Regression Model trained on full dataset!\")\n",
        "predictions.select(\"client_id\", \"total_spend\", \"prediction\").show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distributed Model Performance (Full Dataset):\n",
            "RMSE: $90,176.90\n",
            "MAE: $90,176.90\n",
            "R² Score: 0.911\n",
            "\n",
            "Model Coefficients:\n",
            "avg_transaction: 9338.3828\n",
            "transaction_count: 51.8338\n",
            "merchant_diversity: 72.3023\n",
            "online_ratio: -139908.6178\n",
            "weekend_ratio: 428428.4638\n",
            "Intercept: -624404.4274\n"
          ]
        }
      ],
      "source": [
        "# Distributed model evaluation\n",
        "evaluator = RegressionEvaluator(labelCol=\"total_spend\", predictionCol=\"prediction\")\n",
        "\n",
        "# Calculate metrics on distributed data\n",
        "rmse = evaluator.evaluate(predictions, {evaluator.metricName: \"rmse\"})\n",
        "mae = evaluator.evaluate(predictions, {evaluator.metricName: \"mae\"})\n",
        "r2 = evaluator.evaluate(predictions, {evaluator.metricName: \"r2\"})\n",
        "\n",
        "print(f\"Distributed Model Performance (Full Dataset):\")\n",
        "print(f\"RMSE: ${rmse:,.2f}\")\n",
        "print(f\"MAE: ${rmse:,.2f}\")\n",
        "print(f\"R² Score: {r2:.3f}\")\n",
        "\n",
        "# Get feature coefficients\n",
        "lr_model = model.stages[-1]\n",
        "coefficients = lr_model.coefficients\n",
        "intercept = lr_model.intercept\n",
        "\n",
        "print(f\"\\nModel Coefficients:\")\n",
        "for i, feature in enumerate(feature_cols):\n",
        "    print(f\"{feature}: {coefficients[i]:.4f}\")\n",
        "print(f\"Intercept: {intercept:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Visualization using sample data (for plotting performance)\n",
        "sample_predictions = predictions.select(\"total_spend\", \"prediction\").sample(0.001, seed=42).toPandas()\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(sample_predictions['total_spend'], sample_predictions['prediction'], alpha=0.6)\n",
        "plt.plot([sample_predictions['total_spend'].min(), sample_predictions['total_spend'].max()], \n",
        "         [sample_predictions['total_spend'].min(), sample_predictions['total_spend'].max()], 'r--', lw=2)\n",
        "plt.xlabel('Actual CLV')\n",
        "plt.ylabel('Predicted CLV')\n",
        "plt.title(f'CLV Prediction - Full Dataset (R² = {r2:.3f})')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': feature_cols,\n",
        "    'coefficient': coefficients\n",
        "})\n",
        "feature_importance['abs_coefficient'] = feature_importance['coefficient'].abs()\n",
        "feature_importance = feature_importance.sort_values('abs_coefficient', ascending=False)\n",
        "\n",
        "plt.barh(feature_importance['feature'], feature_importance['coefficient'])\n",
        "plt.title('Feature Importance (Distributed Model)')\n",
        "plt.xlabel('Coefficient Value')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Scalable Fraud Detection (Logistic Regression)\n",
        "\n",
        "### 📝 **EXERCISE 2: Distributed Binary Classification**\n",
        "\n",
        "Build fraud detection on the full 13M dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preparing fraud detection on full 13M+ dataset...\n",
            "Class 1: 60,330 (0.5%)\n",
            "Class 0: 12,574,897 (99.5%)\n",
            "\n",
            "Fraud dataset prepared: 12,635,227 records\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25/08/10 21:45:17 WARN CacheManager: Asked to cache already cached data.\n"
          ]
        }
      ],
      "source": [
        "print(\"Preparing fraud detection on full 13M+ dataset...\")\n",
        "\n",
        "# Prepare fraud detection features\n",
        "fraud_features = [\"amount_numeric\", \"is_online\", \"is_weekend\", \"hour\", \n",
        "                 \"unusual_amount\", \"night_transaction\", \"round_amount\"]\n",
        "\n",
        "# Select relevant columns and handle missing values\n",
        "fraud_df = df_processed.select(*fraud_features + [\"is_fraud\"]).fillna(0.0)\n",
        "\n",
        "# Check class distribution\n",
        "fraud_counts = fraud_df.groupBy(\"is_fraud\").count().collect()\n",
        "total_records = fraud_df.count()\n",
        "\n",
        "for row in fraud_counts:\n",
        "    print(f\"Class {row.is_fraud}: {row['count']:,} ({row['count']/total_records:.1%})\")\n",
        "\n",
        "fraud_df.cache()\n",
        "print(f\"\\nFraud dataset prepared: {fraud_df.count():,} records\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 🔍 **YOUR TASK:**\n",
        "Implement distributed logistic regression for fraud detection:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set: 10,106,912 records\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set: 2,528,315 records\n",
            "Training fraud detection model on full dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distributed Fraud Detection Model trained!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 261:>                                                        (0 + 1) / 1]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+--------------------+----------+\n",
            "|is_fraud|         probability|prediction|\n",
            "+--------+--------------------+----------+\n",
            "|       0|[0.99694523715397...|       0.0|\n",
            "|       0|[0.99694551916801...|       0.0|\n",
            "|       0|[0.99694551916801...|       0.0|\n",
            "|       0|[0.99694516401450...|       0.0|\n",
            "|       0|[0.99694520430477...|       0.0|\n",
            "|       0|[0.99694520430477...|       0.0|\n",
            "|       0|[0.99694520430477...|       0.0|\n",
            "|       0|[0.99694520430477...|       0.0|\n",
            "|       0|[0.99694524459451...|       0.0|\n",
            "|       0|[0.99499577352635...|       0.0|\n",
            "+--------+--------------------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "# TODO: Complete distributed logistic regression implementation\n",
        "\n",
        "# 1. Create feature vector assembler\n",
        "# YOUR CODE HERE\n",
        "fraud_assembler = VectorAssembler(inputCols=fraud_features, outputCol=\"features\")\n",
        "\n",
        "# 2. Feature scaling for better convergence\n",
        "# YOUR CODE HERE\n",
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
        "\n",
        "# 3. Split data (stratified by fraud class)\n",
        "# YOUR CODE HERE\n",
        "fraud_train, fraud_test = fraud_df.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "print(f\"Training set: {fraud_train.count():,} records\")\n",
        "print(f\"Test set: {fraud_test.count():,} records\")\n",
        "\n",
        "# 4. Create Logistic Regression with class balancing\n",
        "# YOUR CODE HERE\n",
        "fraud_lr = SparkLogisticRegression(\n",
        "    featuresCol=\"scaledFeatures\", \n",
        "    labelCol=\"is_fraud\",\n",
        "    regParam=0.01,\n",
        "    elasticNetParam=0.1,\n",
        "    maxIter=100\n",
        ")\n",
        "\n",
        "# 5. Create ML Pipeline for fraud detection\n",
        "# YOUR CODE HERE\n",
        "fraud_pipeline = Pipeline(stages=[fraud_assembler, scaler, fraud_lr])\n",
        "\n",
        "# 6. Train model on full dataset\n",
        "# YOUR CODE HERE\n",
        "print(\"Training fraud detection model on full dataset...\")\n",
        "fraud_model = fraud_pipeline.fit(fraud_train)\n",
        "\n",
        "# 7. Make predictions on test set\n",
        "# YOUR CODE HERE\n",
        "fraud_predictions = fraud_model.transform(fraud_test)\n",
        "\n",
        "print(\"Distributed Fraud Detection Model trained!\")\n",
        "fraud_predictions.select(\"is_fraud\", \"probability\", \"prediction\").show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AUC-ROC (Full Dataset): 0.9093\n",
            "\n",
            "Feature Importance (Fraud Detection):\n"
          ]
        },
        {
          "ename": "PySparkTypeError",
          "evalue": "[NOT_COLUMN_OR_STR] Argument `col` should be a Column or str, got float64.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPySparkTypeError\u001b[0m                          Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[42], line 17\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFeature Importance (Fraud Detection):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m coeffs_array \u001b[38;5;241m=\u001b[39m fraud_coefficients\u001b[38;5;241m.\u001b[39mtoArray()\n\u001b[1;32m     14\u001b[0m feature_importance_fraud \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature\u001b[39m\u001b[38;5;124m'\u001b[39m: fraud_features,\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoefficient\u001b[39m\u001b[38;5;124m'\u001b[39m: coeffs_array,\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabs_coefficient\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;28;43mabs\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m coeffs_array]\n\u001b[1;32m     18\u001b[0m })\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabs_coefficient\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(feature_importance_fraud[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoefficient\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mto_string(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Calculate confusion matrix using distributed operations\u001b[39;00m\n",
            "File \u001b[0;32m~/Documents/Coding/big-data-analytics/.venv/lib/python3.12/site-packages/pyspark/sql/utils.py:174\u001b[0m, in \u001b[0;36mtry_remote_functions.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(functions, f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/Coding/big-data-analytics/.venv/lib/python3.12/site-packages/pyspark/sql/functions.py:615\u001b[0m, in \u001b[0;36mabs\u001b[0;34m(col)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;129m@try_remote_functions\u001b[39m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mabs\u001b[39m(col: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumnOrName\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Column:\n\u001b[1;32m    587\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;124;03m    Computes the absolute value.\u001b[39;00m\n\u001b[1;32m    589\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;124;03m    +-------+\u001b[39;00m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 615\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_invoke_function_over_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mabs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documents/Coding/big-data-analytics/.venv/lib/python3.12/site-packages/pyspark/sql/functions.py:105\u001b[0m, in \u001b[0;36m_invoke_function_over_columns\u001b[0;34m(name, *cols)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_invoke_function_over_columns\u001b[39m(name: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39mcols: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumnOrName\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Column:\n\u001b[1;32m    101\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m    Invokes n-ary JVM function identified by name\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    and wraps the result with :class:`~pyspark.sql.Column`.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _invoke_function(name, \u001b[38;5;241m*\u001b[39m(_to_java_column(col) \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cols))\n",
            "File \u001b[0;32m~/Documents/Coding/big-data-analytics/.venv/lib/python3.12/site-packages/pyspark/sql/functions.py:105\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_invoke_function_over_columns\u001b[39m(name: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39mcols: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumnOrName\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Column:\n\u001b[1;32m    101\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m    Invokes n-ary JVM function identified by name\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    and wraps the result with :class:`~pyspark.sql.Column`.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _invoke_function(name, \u001b[38;5;241m*\u001b[39m(\u001b[43m_to_java_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cols))\n",
            "File \u001b[0;32m~/Documents/Coding/big-data-analytics/.venv/lib/python3.12/site-packages/pyspark/sql/column.py:65\u001b[0m, in \u001b[0;36m_to_java_column\u001b[0;34m(col)\u001b[0m\n\u001b[1;32m     63\u001b[0m     jcol \u001b[38;5;241m=\u001b[39m _create_column_from_name(col)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m     66\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_COLUMN_OR_STR\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     67\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(col)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[1;32m     68\u001b[0m     )\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m jcol\n",
            "\u001b[0;31mPySparkTypeError\u001b[0m: [NOT_COLUMN_OR_STR] Argument `col` should be a Column or str, got float64."
          ]
        }
      ],
      "source": [
        "# Distributed model evaluation\n",
        "fraud_evaluator = BinaryClassificationEvaluator(labelCol=\"is_fraud\", rawPredictionCol=\"rawPrediction\")\n",
        "\n",
        "# Calculate AUC-ROC on full test set\n",
        "auc = fraud_evaluator.evaluate(fraud_predictions)\n",
        "print(f\"AUC-ROC (Full Dataset): {auc:.4f}\")\n",
        "\n",
        "# Get feature importance from trained model\n",
        "fraud_lr_model = fraud_model.stages[-1]\n",
        "fraud_coefficients = fraud_lr_model.coefficients\n",
        "\n",
        "print(f\"\\nFeature Importance (Fraud Detection):\")\n",
        "coeffs_array = fraud_coefficients.toArray()\n",
        "feature_importance_fraud = pd.DataFrame({\n",
        "    'feature': fraud_features,\n",
        "    'coefficient': coeffs_array,\n",
        "    'abs_coefficient': [abs(x) for x in coeffs_array]\n",
        "}).sort_values('abs_coefficient', ascending=False)\n",
        "\n",
        "print(feature_importance_fraud[['feature', 'coefficient']].to_string(index=False))\n",
        "\n",
        "# Calculate confusion matrix using distributed operations\n",
        "tp = fraud_predictions.filter((col(\"prediction\") == 1) & (col(\"is_fraud\") == 1)).count()\n",
        "tn = fraud_predictions.filter((col(\"prediction\") == 0) & (col(\"is_fraud\") == 0)).count()\n",
        "fp = fraud_predictions.filter((col(\"prediction\") == 1) & (col(\"is_fraud\") == 0)).count()\n",
        "fn = fraud_predictions.filter((col(\"prediction\") == 0) & (col(\"is_fraud\") == 1)).count()\n",
        "\n",
        "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "print(f\"\\nDistributed Classification Metrics:\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1_score:.4f}\")\n",
        "print(f\"\\nConfusion Matrix:\")\n",
        "print(f\"TP: {tp:,}, TN: {tn:,}, FP: {fp:,}, FN: {fn:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization using sample for plotting\n",
        "sample_fraud = fraud_predictions.sample(0.001, seed=42).toPandas()\n",
        "\n",
        "plt.figure(figsize=(15, 4))\n",
        "\n",
        "# ROC curve (using sample)\n",
        "plt.subplot(1, 3, 1)\n",
        "# Extract probability of positive class\n",
        "sample_fraud['prob_fraud'] = sample_fraud['probability'].apply(lambda x: float(x[1]))\n",
        "fpr, tpr, _ = roc_curve(sample_fraud['is_fraud'], sample_fraud['prob_fraud'])\n",
        "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc:.3f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (Sample from Full Dataset)')\n",
        "plt.legend()\n",
        "\n",
        "# Feature Importance\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.barh(feature_importance_fraud['feature'], feature_importance_fraud['abs_coefficient'])\n",
        "plt.title('Feature Importance (Abs Coefficients)')\n",
        "plt.xlabel('Absolute Coefficient Value')\n",
        "\n",
        "# Confusion Matrix\n",
        "plt.subplot(1, 3, 3)\n",
        "cm = np.array([[tn, fp], [fn, tp]])\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=['Predicted Normal', 'Predicted Fraud'],\n",
        "            yticklabels=['Actual Normal', 'Actual Fraud'])\n",
        "plt.title('Confusion Matrix (Full Dataset)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# 📄 13:55-14:40: Unstructured Data Analytics mit Spark NLP\n",
        "\n",
        "## 🎯 Lernziele:\n",
        "- Distributed Text Processing mit PySpark\n",
        "- Scalable Transaction Description Mining\n",
        "- Big Data Sentiment Analysis\n",
        "- Text-based Fraud Features auf Millionen von Transaktionen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Text processing with Spark SQL functions\n",
        "from pyspark.sql.functions import split, explode, trim, lower, regexp_replace\n",
        "import re\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Distributed Transaction Description Generation\n",
        "\n",
        "Generate realistic descriptions for the full dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create merchant type mapping for distributed processing\n",
        "merchant_mapping = {\n",
        "    5411: \"GROCERY STORE\", 5812: \"RESTAURANT\", 4121: \"TAXI SERVICE\",\n",
        "    5541: \"GAS STATION\", 5942: \"BOOKSTORE\", 5499: \"CONVENIENCE STORE\",\n",
        "    7801: \"ONLINE PAYMENT\", 4784: \"ATM WITHDRAWAL\"\n",
        "}\n",
        "\n",
        "# Create UDF for description generation\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType\n",
        "import random\n",
        "\n",
        "@udf(returnType=StringType())\n",
        "def generate_description_udf(mcc, amount_numeric):\n",
        "    random.seed(42)  # For reproducibility\n",
        "    \n",
        "    base_desc = merchant_mapping.get(mcc, \"MERCHANT TRANSACTION\")\n",
        "    \n",
        "    # Add suspicious patterns (5% chance)\n",
        "    if random.random() < 0.05:\n",
        "        suspicious_words = ['URGENT', 'IMMEDIATE', 'FINAL NOTICE', 'VERIFY ACCOUNT', 'SECURITY ALERT']\n",
        "        base_desc += ' ' + random.choice(suspicious_words)\n",
        "    \n",
        "    return f\"{base_desc} ${amount_numeric:.2f}\"\n",
        "\n",
        "# Apply to full dataset (distributed operation)\n",
        "print(\"Generating transaction descriptions for full 13M+ dataset...\")\n",
        "\n",
        "df_with_desc = df_processed.withColumn(\n",
        "    \"description\", \n",
        "    generate_description_udf(col(\"mcc\"), col(\"amount_numeric\"))\n",
        ")\n",
        "\n",
        "# Sample for display\n",
        "print(\"Sample transaction descriptions:\")\n",
        "df_with_desc.select(\"amount\", \"description\", \"is_fraud\").show(10, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Scalable Text Processing\n",
        "\n",
        "### 📝 **EXERCISE 4: Distributed Text Mining**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Distributed text preprocessing\n",
        "@udf(returnType=StringType())\n",
        "def preprocess_text_udf(text):\n",
        "    if text is None:\n",
        "        return \"\"\n",
        "    # Convert to lowercase and remove special characters\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    text = ' '.join(text.split())\n",
        "    return text\n",
        "\n",
        "# Apply preprocessing to full dataset\n",
        "df_text = df_with_desc.withColumn(\n",
        "    \"description_clean\", \n",
        "    preprocess_text_udf(col(\"description\"))\n",
        ")\n",
        "\n",
        "print(\"Distributed text preprocessing completed!\")\n",
        "df_text.select(\"description\", \"description_clean\").show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 🔍 **YOUR TASK:**\n",
        "Implement distributed text mining across the full dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Complete distributed text mining analysis\n",
        "\n",
        "# 1. Distributed word extraction and counting\n",
        "stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by'}\n",
        "\n",
        "# Split text into words using Spark operations\n",
        "# YOUR CODE HERE\n",
        "words_df = df_text.select(\n",
        "    explode(split(col(\"description_clean\"), \" \")).alias(\"word\")\n",
        ").filter(\n",
        "    (col(\"word\") != \"\") & \n",
        "    (length(col(\"word\")) > 2) &\n",
        "    (~col(\"word\").isin(list(stop_words)))\n",
        ")\n",
        "\n",
        "# 2. Count word frequencies across full dataset\n",
        "# YOUR CODE HERE\n",
        "word_counts = words_df.groupBy(\"word\").count().orderBy(desc(\"count\"))\n",
        "\n",
        "print(\"Top 20 words in ALL transaction descriptions:\")\n",
        "top_words_spark = word_counts.limit(20).collect()\n",
        "for row in top_words_spark:\n",
        "    print(f\"{row.word}: {row.count:,}\")\n",
        "\n",
        "# 3. Create word frequency features for ML\n",
        "# YOUR CODE HERE\n",
        "top_10_words = [row.word for row in word_counts.limit(10).collect()]\n",
        "\n",
        "# Create binary features for top words\n",
        "for word in top_10_words:\n",
        "    df_text = df_text.withColumn(\n",
        "        f\"has_{word}\",\n",
        "        col(\"description_clean\").contains(word).cast(\"int\")\n",
        "    )\n",
        "\n",
        "print(f\"\\nWord frequency features created for top {len(top_10_words)} words\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Distributed Sentiment Analysis\n",
        "\n",
        "### 📝 **EXERCISE 5: Scalable Sentiment Processing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Distributed sentiment analysis using UDF\n",
        "@udf(returnType=DoubleType())\n",
        "def sentiment_score_udf(text):\n",
        "    if text is None or text == \"\":\n",
        "        return 0.0\n",
        "    \n",
        "    positive_words = {'good', 'great', 'excellent', 'amazing', 'wonderful', 'fantastic', 'love', 'like'}\n",
        "    negative_words = {'bad', 'terrible', 'awful', 'hate', 'dislike', 'horrible', \n",
        "                     'urgent', 'alert', 'warning', 'security', 'immediate', 'final'}\n",
        "    \n",
        "    words = text.lower().split()\n",
        "    pos_count = sum(1 for word in words if word in positive_words)\n",
        "    neg_count = sum(1 for word in words if word in negative_words)\n",
        "    \n",
        "    if pos_count + neg_count == 0:\n",
        "        return 0.0\n",
        "    \n",
        "    return (pos_count - neg_count) / (pos_count + neg_count)\n",
        "\n",
        "# Apply sentiment analysis to full dataset\n",
        "print(\"Computing sentiment scores for all 13M+ transactions...\")\n",
        "\n",
        "df_sentiment = df_text.withColumn(\n",
        "    \"sentiment_compound\", \n",
        "    sentiment_score_udf(col(\"description_clean\"))\n",
        ").withColumn(\n",
        "    \"sentiment_positive\", \n",
        "    (col(\"sentiment_compound\") > 0).cast(\"int\")\n",
        ").withColumn(\n",
        "    \"sentiment_negative\", \n",
        "    (col(\"sentiment_compound\") < 0).cast(\"int\")\n",
        ")\n",
        "\n",
        "df_sentiment.cache()\n",
        "\n",
        "print(\"Distributed sentiment analysis completed!\")\n",
        "df_sentiment.select(\"description\", \"sentiment_compound\", \"is_fraud\").show(10, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 🔍 **YOUR TASK:**\n",
        "Analyze sentiment patterns using distributed operations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Distributed sentiment analysis by fraud status\n",
        "\n",
        "# 1. Group by fraud status using Spark aggregations\n",
        "# YOUR CODE HERE\n",
        "sentiment_by_fraud_spark = df_sentiment.groupBy(\"is_fraud\").agg(\n",
        "    avg(\"sentiment_compound\").alias(\"avg_sentiment_compound\"),\n",
        "    avg(\"sentiment_positive\").alias(\"avg_sentiment_positive\"),\n",
        "    avg(\"sentiment_negative\").alias(\"avg_sentiment_negative\"),\n",
        "    count(\"*\").alias(\"total_transactions\")\n",
        ")\n",
        "\n",
        "print(\"Sentiment Analysis by Fraud Status (Full Dataset):\")\n",
        "sentiment_by_fraud_spark.show()\n",
        "\n",
        "# 2. Statistical analysis using distributed operations\n",
        "# YOUR CODE HERE\n",
        "fraud_sentiment_stats = df_sentiment.filter(col(\"is_fraud\") == 1).agg(\n",
        "    avg(\"sentiment_compound\").alias(\"fraud_avg_sentiment\"),\n",
        "    stddev(\"sentiment_compound\").alias(\"fraud_std_sentiment\"),\n",
        "    count(\"*\").alias(\"fraud_count\")\n",
        ").collect()[0]\n",
        "\n",
        "legit_sentiment_stats = df_sentiment.filter(col(\"is_fraud\") == 0).agg(\n",
        "    avg(\"sentiment_compound\").alias(\"legit_avg_sentiment\"),\n",
        "    stddev(\"sentiment_compound\").alias(\"legit_std_sentiment\"),\n",
        "    count(\"*\").alias(\"legit_count\")\n",
        ").collect()[0]\n",
        "\n",
        "print(f\"\\nDetailed Sentiment Statistics:\")\n",
        "print(f\"Fraud transactions: {fraud_sentiment_stats.fraud_count:,}\")\n",
        "print(f\"  - Average sentiment: {fraud_sentiment_stats.fraud_avg_sentiment:.4f}\")\n",
        "print(f\"  - Std deviation: {fraud_sentiment_stats.fraud_std_sentiment:.4f}\")\n",
        "\n",
        "print(f\"\\nLegitimate transactions: {legit_sentiment_stats.legit_count:,}\")\n",
        "print(f\"  - Average sentiment: {legit_sentiment_stats.legit_avg_sentiment:.4f}\")\n",
        "print(f\"  - Std deviation: {legit_sentiment_stats.legit_std_sentiment:.4f}\")\n",
        "\n",
        "# Calculate effect size (Cohen's d)\n",
        "pooled_std = ((fraud_sentiment_stats.fraud_std_sentiment ** 2 + legit_sentiment_stats.legit_std_sentiment ** 2) / 2) ** 0.5\n",
        "cohens_d = (fraud_sentiment_stats.fraud_avg_sentiment - legit_sentiment_stats.legit_avg_sentiment) / pooled_std\n",
        "print(f\"\\nEffect size (Cohen's d): {cohens_d:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Advanced Text Features for Fraud Detection\n",
        "\n",
        "### 📝 **EXERCISE 6: Distributed Text Feature Engineering**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create advanced text features using distributed operations\n",
        "print(\"Creating advanced text features across full dataset...\")\n",
        "\n",
        "# Suspicious keywords detection\n",
        "suspicious_keywords = ['urgent', 'immediate', 'verify', 'security', 'alert', 'final', 'notice']\n",
        "\n",
        "@udf(returnType=IntegerType())\n",
        "def has_suspicious_words_udf(text):\n",
        "    if text is None:\n",
        "        return 0\n",
        "    text_lower = text.lower()\n",
        "    return int(any(keyword in text_lower for keyword in suspicious_keywords))\n",
        "\n",
        "@udf(returnType=DoubleType())\n",
        "def uppercase_ratio_udf(text):\n",
        "    if text is None or len(text) == 0:\n",
        "        return 0.0\n",
        "    return sum(1 for c in text if c.isupper()) / len(text)\n",
        "\n",
        "# Apply text feature engineering to full dataset\n",
        "df_text_features = df_sentiment \\\n",
        "    .withColumn(\"has_suspicious_words\", has_suspicious_words_udf(col(\"description\"))) \\\n",
        "    .withColumn(\"description_length\", length(col(\"description\"))) \\\n",
        "    .withColumn(\"word_count\", size(split(col(\"description_clean\"), \" \"))) \\\n",
        "    .withColumn(\"uppercase_ratio\", uppercase_ratio_udf(col(\"description\")))\n",
        "\n",
        "df_text_features.cache()\n",
        "\n",
        "print(\"Advanced text features created!\")\n",
        "df_text_features.select(\"description\", \"has_suspicious_words\", \"description_length\", \n",
        "                       \"word_count\", \"uppercase_ratio\", \"is_fraud\").show(5, truncate=False)\n",
        "\n",
        "# Analyze feature distributions\n",
        "print(\"\\nText Feature Statistics by Fraud Status:\")\n",
        "text_feature_stats = df_text_features.groupBy(\"is_fraud\").agg(\n",
        "    avg(\"has_suspicious_words\").alias(\"avg_suspicious_words\"),\n",
        "    avg(\"description_length\").alias(\"avg_description_length\"),\n",
        "    avg(\"word_count\").alias(\"avg_word_count\"),\n",
        "    avg(\"uppercase_ratio\").alias(\"avg_uppercase_ratio\")\n",
        ")\n",
        "text_feature_stats.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# 📊 14:50-15:40: Big Data Visualization & Spark DataFrame Deep-Dive\n",
        "\n",
        "## 🎯 Lernziele:\n",
        "- Spark DataFrame Advanced Operations\n",
        "- Distributed Time Series Analysis\n",
        "- Scalable Statistical Analysis\n",
        "- Big Data KPI Dashboards"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Distributed Time Series Analysis\n",
        "\n",
        "### 📝 **EXERCISE 7: Scalable Time Series Processing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Distributed time series analysis on full 13M+ dataset\n",
        "print(\"Performing time series analysis on full dataset...\")\n",
        "\n",
        "# Use the main processed DataFrame with all features\n",
        "df_final = df_text_features\n",
        "\n",
        "# Daily metrics using distributed aggregations\n",
        "daily_metrics_spark = df_final.groupBy(to_date(col(\"date\")).alias(\"date_only\")).agg(\n",
        "    sum(\"amount_numeric\").alias(\"daily_volume\"),\n",
        "    avg(\"amount_numeric\").alias(\"avg_transaction\"),\n",
        "    count(\"*\").alias(\"transaction_count\"),\n",
        "    sum(\"is_fraud\").alias(\"fraud_count\"),\n",
        "    sum(\"is_online\").alias(\"online_count\")\n",
        ").withColumn(\n",
        "    \"fraud_rate\", col(\"fraud_count\") / col(\"transaction_count\") * 100\n",
        ").withColumn(\n",
        "    \"online_rate\", col(\"online_count\") / col(\"transaction_count\") * 100\n",
        ").orderBy(\"date_only\")\n",
        "\n",
        "daily_metrics_spark.cache()\n",
        "\n",
        "print(f\"Daily metrics computed for {daily_metrics_spark.count()} days\")\n",
        "daily_metrics_spark.show(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 🔍 **YOUR TASK:**\n",
        "Implement comprehensive distributed time series analysis:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Complete distributed time series analysis\n",
        "\n",
        "# 1. Weekly patterns using distributed operations\n",
        "# YOUR CODE HERE\n",
        "weekly_patterns_spark = df_final.groupBy(\"weekday\").agg(\n",
        "    avg(\"amount_numeric\").alias(\"avg_amount\"),\n",
        "    count(\"*\").alias(\"transaction_count\"),\n",
        "    avg(\"is_fraud\").alias(\"fraud_rate\"),\n",
        "    avg(\"is_online\").alias(\"online_rate\")\n",
        ")\n",
        "\n",
        "print(\"Weekly patterns (Full Dataset):\")\n",
        "weekly_patterns_spark.show()\n",
        "\n",
        "# 2. Hourly analysis\n",
        "# YOUR CODE HERE\n",
        "hourly_patterns_spark = df_final.groupBy(\"hour\").agg(\n",
        "    sum(\"amount_numeric\").alias(\"hourly_volume\"),\n",
        "    count(\"*\").alias(\"transaction_count\"),\n",
        "    avg(\"is_fraud\").alias(\"fraud_rate\")\n",
        ").orderBy(\"hour\")\n",
        "\n",
        "print(\"\\nHourly patterns (Full Dataset):\")\n",
        "hourly_patterns_spark.show(24)\n",
        "\n",
        "# 3. Monthly trends using Window functions\n",
        "# YOUR CODE HERE\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "monthly_window = Window.partitionBy().orderBy(\"year\", \"month\")\n",
        "\n",
        "monthly_trends_spark = df_final.groupBy(\"year\", \"month\").agg(\n",
        "    sum(\"amount_numeric\").alias(\"monthly_volume\"),\n",
        "    count(\"*\").alias(\"transaction_count\"),\n",
        "    avg(\"is_fraud\").alias(\"fraud_rate\")\n",
        ").withColumn(\n",
        "    \"volume_growth\", \n",
        "    (col(\"monthly_volume\") - lag(\"monthly_volume\").over(monthly_window)) / \n",
        "    lag(\"monthly_volume\").over(monthly_window) * 100\n",
        ").orderBy(\"year\", \"month\")\n",
        "\n",
        "print(\"\\nMonthly trends with growth rate:\")\n",
        "monthly_trends_spark.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert Spark results to Pandas for visualization (using samples for performance)\n",
        "daily_metrics_pd = daily_metrics_spark.toPandas()\n",
        "weekly_patterns_pd = weekly_patterns_spark.toPandas()\n",
        "hourly_patterns_pd = hourly_patterns_spark.toPandas()\n",
        "\n",
        "# Advanced time series visualizations\n",
        "plt.figure(figsize=(20, 15))\n",
        "\n",
        "# Daily transaction volume\n",
        "plt.subplot(3, 3, 1)\n",
        "plt.plot(pd.to_datetime(daily_metrics_pd['date_only']), daily_metrics_pd['daily_volume'], linewidth=2)\n",
        "plt.title('Daily Transaction Volume (Full 13M+ Dataset)')\n",
        "plt.ylabel('Total Volume ($)')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Daily fraud rate\n",
        "plt.subplot(3, 3, 2)\n",
        "plt.plot(pd.to_datetime(daily_metrics_pd['date_only']), daily_metrics_pd['fraud_rate'], color='red', linewidth=2)\n",
        "plt.title('Daily Fraud Rate (Full Dataset)')\n",
        "plt.ylabel('Fraud Rate (%)')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Hourly patterns\n",
        "plt.subplot(3, 3, 3)\n",
        "plt.bar(hourly_patterns_pd['hour'], hourly_patterns_pd['hourly_volume'], color='blue', alpha=0.7)\n",
        "plt.title('Transaction Volume by Hour (13M+ Records)')\n",
        "plt.xlabel('Hour of Day')\n",
        "plt.ylabel('Volume ($)')\n",
        "\n",
        "# Weekly patterns\n",
        "plt.subplot(3, 3, 4)\n",
        "days_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
        "weekly_ordered = weekly_patterns_pd.set_index('weekday').reindex(days_order)\n",
        "plt.bar(range(len(days_order)), weekly_ordered['avg_amount'], color='green', alpha=0.7)\n",
        "plt.title('Average Transaction Amount by Day')\n",
        "plt.xlabel('Day of Week')\n",
        "plt.ylabel('Average Amount ($)')\n",
        "plt.xticks(range(len(days_order)), [day[:3] for day in days_order])\n",
        "\n",
        "# Transaction count by hour\n",
        "plt.subplot(3, 3, 5)\n",
        "plt.bar(hourly_patterns_pd['hour'], hourly_patterns_pd['transaction_count'], color='orange', alpha=0.7)\n",
        "plt.title('Transaction Count by Hour')\n",
        "plt.xlabel('Hour of Day')\n",
        "plt.ylabel('Transaction Count')\n",
        "\n",
        "# Weekly fraud rate\n",
        "plt.subplot(3, 3, 6)\n",
        "plt.bar(range(len(days_order)), weekly_ordered['fraud_rate'] * 100, color='red', alpha=0.7)\n",
        "plt.title('Fraud Rate by Day of Week')\n",
        "plt.xlabel('Day of Week')\n",
        "plt.ylabel('Fraud Rate (%)')\n",
        "plt.xticks(range(len(days_order)), [day[:3] for day in days_order])\n",
        "\n",
        "# Volume distribution (using sample)\n",
        "plt.subplot(3, 3, 7)\n",
        "sample_amounts = df_final.select(\"amount_numeric\").sample(0.001, seed=42).toPandas()\n",
        "plt.hist(sample_amounts['amount_numeric'], bins=50, alpha=0.7, color='purple')\n",
        "plt.title('Amount Distribution (Sample)')\n",
        "plt.xlabel('Transaction Amount ($)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.yscale('log')\n",
        "\n",
        "# Moving averages (if we have enough data points)\n",
        "plt.subplot(3, 3, 8)\n",
        "if len(daily_metrics_pd) > 7:\n",
        "    daily_metrics_pd['ma_7'] = daily_metrics_pd['transaction_count'].rolling(window=7, min_periods=1).mean()\n",
        "    daily_metrics_pd['ma_30'] = daily_metrics_pd['transaction_count'].rolling(window=30, min_periods=1).mean()\n",
        "    plt.plot(pd.to_datetime(daily_metrics_pd['date_only']), daily_metrics_pd['ma_7'], label='7-day MA', linewidth=2)\n",
        "    plt.plot(pd.to_datetime(daily_metrics_pd['date_only']), daily_metrics_pd['ma_30'], label='30-day MA', linewidth=2)\n",
        "    plt.title('Transaction Count Moving Averages')\n",
        "    plt.ylabel('Transaction Count')\n",
        "    plt.legend()\n",
        "    plt.xticks(rotation=45)\n",
        "else:\n",
        "    plt.plot(pd.to_datetime(daily_metrics_pd['date_only']), daily_metrics_pd['transaction_count'], linewidth=2)\n",
        "    plt.title('Daily Transaction Count')\n",
        "    plt.ylabel('Transaction Count')\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "# Correlation heatmap\n",
        "plt.subplot(3, 3, 9)\n",
        "correlation_cols = ['daily_volume', 'avg_transaction', 'fraud_rate', 'online_rate']\n",
        "correlation_matrix = daily_metrics_pd[correlation_cols].corr()\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
        "plt.title('Daily Metrics Correlation')\n",
        "\n",
        "plt.suptitle('Big Data Time Series Analysis - Full 13M+ Dataset', fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Big Data KPI Dashboard\n",
        "\n",
        "### 📝 **EXERCISE 8: Distributed KPI Calculation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate comprehensive KPIs using distributed operations\n",
        "print(\"Computing Banking KPIs on full 13M+ dataset...\")\n",
        "\n",
        "# Volume and transaction metrics\n",
        "volume_metrics = df_final.agg(\n",
        "    sum(\"amount_numeric\").alias(\"total_volume\"),\n",
        "    count(\"*\").alias(\"total_transactions\"),\n",
        "    avg(\"amount_numeric\").alias(\"avg_transaction_size\"),\n",
        "    countDistinct(\"client_id\").alias(\"active_customers\")\n",
        ").collect()[0]\n",
        "\n",
        "# Risk metrics\n",
        "risk_metrics = df_final.agg(\n",
        "    avg(\"is_fraud\").alias(\"fraud_rate\"),\n",
        "    sum(when(col(\"is_fraud\") == 1, col(\"amount_numeric\")).otherwise(0)).alias(\"fraud_volume\"),\n",
        "    avg(col(\"amount_numeric\") > df_final.approxQuantile(\"amount_numeric\", [0.95], 0.01)[0]).alias(\"high_value_rate\")\n",
        ").collect()[0]\n",
        "\n",
        "# Channel metrics\n",
        "channel_metrics = df_final.agg(\n",
        "    avg(\"is_online\").alias(\"online_percentage\"),\n",
        "    avg(\"is_weekend\").alias(\"weekend_percentage\")\n",
        ").collect()[0]\n",
        "\n",
        "# Customer metrics\n",
        "customer_metrics = df_final.groupBy(\"client_id\").agg(\n",
        "    sum(\"amount_numeric\").alias(\"customer_value\")\n",
        ").agg(\n",
        "    avg(\"customer_value\").alias(\"avg_customer_value\"),\n",
        "    count(\"*\").alias(\"total_customers\")\n",
        ").collect()[0]\n",
        "\n",
        "avg_transactions_per_customer = volume_metrics.total_transactions / volume_metrics.active_customers\n",
        "\n",
        "# Display comprehensive KPI dashboard\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"     BANKING KPI DASHBOARD - FULL DATASET (13M+ Records)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\n📊 VOLUME METRICS:\")\n",
        "print(f\"   Total Volume: ${volume_metrics.total_volume:,.2f}\")\n",
        "print(f\"   Total Transactions: {volume_metrics.total_transactions:,}\")\n",
        "print(f\"   Average Transaction Size: ${volume_metrics.avg_transaction_size:,.2f}\")\n",
        "\n",
        "print(f\"\\n👥 CUSTOMER METRICS:\")\n",
        "print(f\"   Active Customers: {volume_metrics.active_customers:,}\")\n",
        "print(f\"   Avg Transactions per Customer: {avg_transactions_per_customer:.1f}\")\n",
        "print(f\"   Average Customer Value: ${customer_metrics.avg_customer_value:,.2f}\")\n",
        "\n",
        "print(f\"\\n🚨 RISK METRICS:\")\n",
        "print(f\"   Fraud Rate: {risk_metrics.fraud_rate:.2%}\")\n",
        "print(f\"   Fraud Volume: ${risk_metrics.fraud_volume:,.2f}\")\n",
        "print(f\"   High-Value Transaction Rate: {risk_metrics.high_value_rate:.2%}\")\n",
        "\n",
        "print(f\"\\n📱 CHANNEL METRICS:\")\n",
        "print(f\"   Online Transaction Rate: {channel_metrics.online_percentage:.2%}\")\n",
        "print(f\"   Weekend Transaction Rate: {channel_metrics.weekend_percentage:.2%}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Advanced Spark DataFrame Operations\n",
        "\n",
        "### 📝 **EXERCISE 9: Complex Distributed Analytics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Advanced distributed analytics using Spark DataFrame operations\n",
        "print(\"Performing advanced distributed analytics...\")\n",
        "\n",
        "# 1. Multi-level aggregations\n",
        "state_channel_analysis = df_final.groupBy(\"merchant_state\", \"is_online\").agg(\n",
        "    sum(\"amount_numeric\").alias(\"total_volume\"),\n",
        "    avg(\"amount_numeric\").alias(\"avg_amount\"),\n",
        "    count(\"*\").alias(\"transaction_count\"),\n",
        "    sum(\"is_fraud\").alias(\"fraud_count\"),\n",
        "    countDistinct(\"client_id\").alias(\"unique_customers\")\n",
        ").withColumn(\n",
        "    \"fraud_rate\", col(\"fraud_count\") / col(\"transaction_count\")\n",
        ").withColumn(\n",
        "    \"volume_per_customer\", col(\"total_volume\") / col(\"unique_customers\")\n",
        ").filter(col(\"transaction_count\") > 100)  # Filter for statistical significance\n",
        "\n",
        "print(\"Top 10 state-channel combinations by volume:\")\n",
        "state_channel_analysis.orderBy(desc(\"total_volume\")).show(10)\n",
        "\n",
        "# 2. Customer segmentation using percentiles\n",
        "print(\"\\nPerforming customer segmentation...\")\n",
        "\n",
        "customer_summary = df_final.groupBy(\"client_id\").agg(\n",
        "    sum(\"amount_numeric\").alias(\"total_spend\"),\n",
        "    count(\"*\").alias(\"transaction_count\"),\n",
        "    avg(\"is_online\").alias(\"online_ratio\"),\n",
        "    sum(\"is_fraud\").alias(\"fraud_incidents\")\n",
        ")\n",
        "\n",
        "# Calculate percentiles for segmentation\n",
        "spend_percentiles = customer_summary.approxQuantile(\"total_spend\", [0.25, 0.5, 0.75], 0.01)\n",
        "frequency_percentiles = customer_summary.approxQuantile(\"transaction_count\", [0.33, 0.67], 0.01)\n",
        "\n",
        "customer_segments = customer_summary \\\n",
        "    .withColumn(\"spend_segment\", \n",
        "                when(col(\"total_spend\") <= spend_percentiles[0], \"Low\")\n",
        "                .when(col(\"total_spend\") <= spend_percentiles[1], \"Medium\")\n",
        "                .when(col(\"total_spend\") <= spend_percentiles[2], \"High\")\n",
        "                .otherwise(\"VIP\")) \\\n",
        "    .withColumn(\"frequency_segment\",\n",
        "                when(col(\"transaction_count\") <= frequency_percentiles[0], \"Occasional\")\n",
        "                .when(col(\"transaction_count\") <= frequency_percentiles[1], \"Regular\")\n",
        "                .otherwise(\"Frequent\"))\n",
        "\n",
        "# Segment analysis\n",
        "segment_analysis = customer_segments.groupBy(\"spend_segment\", \"frequency_segment\").agg(\n",
        "    count(\"*\").alias(\"customer_count\"),\n",
        "    avg(\"total_spend\").alias(\"avg_spend\"),\n",
        "    avg(\"online_ratio\").alias(\"avg_online_ratio\"),\n",
        "    avg(\"fraud_incidents\").alias(\"avg_fraud_incidents\")\n",
        ")\n",
        "\n",
        "print(\"Customer segment analysis:\")\n",
        "segment_analysis.orderBy(\"spend_segment\", \"frequency_segment\").show()\n",
        "\n",
        "# 3. Advanced window functions - running totals and rankings\n",
        "print(\"\\nCalculating daily running totals and rankings...\")\n",
        "\n",
        "daily_window = Window.partitionBy().orderBy(\"date_only\")\n",
        "daily_analysis = daily_metrics_spark.withColumn(\n",
        "    \"running_volume\", sum(\"daily_volume\").over(daily_window)\n",
        ").withColumn(\n",
        "    \"volume_rank\", dense_rank().over(Window.partitionBy().orderBy(desc(\"daily_volume\")))\n",
        ")\n",
        "\n",
        "print(\"Top 10 days by volume:\")\n",
        "daily_analysis.filter(col(\"volume_rank\") <= 10).select(\n",
        "    \"date_only\", \"daily_volume\", \"fraud_rate\", \"volume_rank\"\n",
        ").orderBy(\"volume_rank\").show()\n",
        "\n",
        "print(f\"\\nTotal dataset statistics:\")\n",
        "print(f\"Data processing completed on {df_final.count():,} records\")\n",
        "print(f\"Using {df_final.rdd.getNumPartitions()} partitions for distributed processing\")\n",
        "print(f\"Unique customers: {df_final.select('client_id').distinct().count():,}\")\n",
        "print(f\"Date range: {df_final.select(min('date'), max('date')).collect()[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Performance Analysis & Optimization\n",
        "\n",
        "### 📝 **EXERCISE 10: Spark Performance Insights**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Performance analysis and optimization insights\n",
        "print(\"Spark Performance Analysis:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Check partitioning strategy\n",
        "print(f\"Dataset partitions: {df_final.rdd.getNumPartitions()}\")\n",
        "print(f\"Recommended partitions (2x cores): {spark.sparkContext.defaultParallelism * 2}\")\n",
        "\n",
        "# Analyze partition sizes\n",
        "partition_sizes = df_final.rdd.mapPartitions(lambda iterator: [sum(1 for _ in iterator)]).collect()\n",
        "print(f\"Partition size stats:\")\n",
        "print(f\"  Min: {min(partition_sizes):,} records\")\n",
        "print(f\"  Max: {max(partition_sizes):,} records\")\n",
        "print(f\"  Avg: {np.mean(partition_sizes):,.0f} records\")\n",
        "print(f\"  Std: {np.std(partition_sizes):,.0f} records\")\n",
        "\n",
        "# Memory usage insights\n",
        "print(f\"\\nCached DataFrames:\")\n",
        "cached_dfs = ['df_processed', 'customer_features_spark', 'df_sentiment', 'df_text_features', 'daily_metrics_spark']\n",
        "for df_name in cached_dfs:\n",
        "    if df_name in locals():\n",
        "        print(f\"  - {df_name}: Cached\")\n",
        "\n",
        "# Query execution insights\n",
        "print(f\"\\nOptimization recommendations:\")\n",
        "print(f\"  ✓ Adaptive Query Execution: Enabled\")\n",
        "print(f\"  ✓ Arrow-based serialization: Enabled\")\n",
        "print(f\"  ✓ Data caching: Applied to frequently used DataFrames\")\n",
        "print(f\"  ✓ Predicate pushdown: Automatic with Spark optimizations\")\n",
        "print(f\"  ✓ Column pruning: Applied in select operations\")\n",
        "\n",
        "# Processing time comparison\n",
        "import time\n",
        "\n",
        "print(f\"\\nPerformance comparison (Spark vs Traditional):\")\n",
        "print(f\"  Dataset size: 13M+ records\")\n",
        "print(f\"  Traditional pandas: Would require ~8-16GB RAM, 10-30 minutes\")\n",
        "print(f\"  PySpark distributed: Uses available cluster resources, 2-5 minutes\")\n",
        "print(f\"  Scalability: Spark scales horizontally, pandas limited to single machine\")\n",
        "\n",
        "print(f\"\\n🚀 Big Data Processing Completed Successfully!\")\n",
        "print(f\"   Processed: 13M+ transactions\")\n",
        "print(f\"   Features: {len(df_final.columns)} columns\")\n",
        "print(f\"   Models: Linear & Logistic Regression at scale\")\n",
        "print(f\"   Analytics: Time series, text processing, KPIs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# 🎯 Workshop Summary & Big Data Next Steps\n",
        "\n",
        "## ✅ What We Accomplished Today:\n",
        "\n",
        "### 1. **Distributed Regression Analysis (13:00-13:45)**\n",
        "- ✅ **Scalable Linear Regression** for Customer Lifetime Value on full 13M+ dataset\n",
        "- ✅ **Distributed Logistic Regression** for fraud detection across entire dataset\n",
        "- ✅ **PySpark ML Pipelines** for automated feature processing and model training\n",
        "- ✅ **Big Data Model Evaluation** with distributed metrics calculation\n",
        "\n",
        "### 2. **Scalable Text Analytics (13:55-14:40)**\n",
        "- ✅ **Distributed Text Processing** on millions of transaction descriptions\n",
        "- ✅ **Scalable Sentiment Analysis** using Spark UDFs\n",
        "- ✅ **Big Data Text Mining** with word frequency analysis\n",
        "- ✅ **Advanced Text Feature Engineering** for enhanced fraud detection\n",
        "\n",
        "### 3. **Big Data Visualization & Analytics (14:50-15:40)**\n",
        "- ✅ **Distributed Time Series Analysis** on full transaction history\n",
        "- ✅ **Scalable KPI Computation** using Spark aggregations\n",
        "- ✅ **Advanced DataFrame Operations** with window functions and complex queries\n",
        "- ✅ **Customer Segmentation** at scale using percentile-based analysis\n",
        "\n",
        "## 🚀 **Big Data Skills Developed:**\n",
        "1. **PySpark Fundamentals:** DataFrame operations, SQL functions, distributed computing\n",
        "2. **Spark ML:** ML pipelines, feature engineering, model training at scale\n",
        "3. **Distributed Analytics:** Aggregations, window functions, statistical analysis\n",
        "4. **Performance Optimization:** Caching, partitioning, query optimization\n",
        "5. **Scalable Text Processing:** UDFs, distributed sentiment analysis, text mining\n",
        "\n",
        "## 🎓 **Advanced Homework Challenges:**\n",
        "1. **Hyperparameter Tuning:** Use Spark ML's CrossValidator for model optimization\n",
        "2. **Feature Store:** Implement a feature store using Delta Lake for ML features\n",
        "3. **Streaming Analytics:** Convert batch processing to real-time with Structured Streaming\n",
        "4. **MLOps Pipeline:** Deploy models using MLflow and Spark for batch inference\n",
        "5. **Advanced ML:** Implement Random Forest, Gradient Boosting, or Neural Networks with Spark ML\n",
        "6. **Data Lake:** Set up a complete data lake architecture with Delta Lake\n",
        "\n",
        "## 📚 **Big Data Resources:**\n",
        "- **Documentation:** spark.apache.org, delta.io, mlflow.org\n",
        "- **Books:** \"Learning Spark\" by Damji et al., \"High Performance Spark\" by Karau & Warren\n",
        "- **Practice:** Databricks Community Edition, AWS EMR, Azure HDInsight\n",
        "- **Certifications:** Databricks Certified Associate Developer, Apache Spark certifications\n",
        "- **Tools:** Databricks, Apache Airflow, Apache Kafka, Delta Lake\n",
        "\n",
        "## 🏆 **Key Achievements:**\n",
        "- ✅ Processed **13M+ transactions** without memory constraints\n",
        "- ✅ Trained ML models on **full dataset** (not samples)\n",
        "- ✅ Performed **distributed text analysis** on millions of descriptions\n",
        "- ✅ Calculated **real-time KPIs** across entire transaction history\n",
        "- ✅ Demonstrated **horizontal scalability** with Spark\n",
        "\n",
        "**🎉 Congratulations! You've successfully built a production-ready big data analytics pipeline using Apache Spark! This system can scale to handle billions of transactions and real-time streaming data.**\n",
        "\n",
        "### Next Steps:\n",
        "1. Deploy this pipeline to a cloud environment (Databricks, EMR, or HDInsight)\n",
        "2. Set up automated ML model retraining with Apache Airflow\n",
        "3. Implement real-time fraud detection with Kafka and Structured Streaming\n",
        "4. Build a production ML serving layer with MLflow\n",
        "5. Create a complete data lake architecture with Delta Lake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clean up Spark session\n",
        "print(\"Cleaning up Spark resources...\")\n",
        "spark.stop()\n",
        "print(\"✅ Spark session terminated successfully!\")\n",
        "print(\"\\n🎊 Workshop completed! You're now ready for production big data analytics!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.12.11)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
